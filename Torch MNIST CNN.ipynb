{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:14.247182900Z",
     "start_time": "2023-08-22T18:41:10.952165Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.multiprocessing as mp\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:14.280680900Z",
     "start_time": "2023-08-22T18:41:14.247182900Z"
    }
   },
   "id": "933da6c2a2114ab1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class AddGaussianNoise(nn.Module):\n",
    "    def __init__(self, mean=0., std=1., *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size(), device=device) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:14.295507400Z",
     "start_time": "2023-08-22T18:41:14.281994600Z"
    }
   },
   "id": "2318a050c76b8a39"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "test_input_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_input_transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_run_transform = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=(-25,25), translate=(0.1,0.1), scale=(0.8, 1.2)),\n",
    "    AddGaussianNoise(mean=0.0,std=0.02)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:14.300135900Z",
     "start_time": "2023-08-22T18:41:14.294503500Z"
    }
   },
   "id": "27750d4c80e649c0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "training_data = datasets.EMNIST(root=\"Torch MNIST\", split=\"digits\", train=True,download=True, transform=train_input_transform)\n",
    "test_data = datasets.EMNIST(root=\"Torch MNIST\", split=\"digits\", train=False,download=True, transform=test_input_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:14.455146600Z",
     "start_time": "2023-08-22T18:41:14.299139600Z"
    }
   },
   "id": "2883061f93593dce"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "4096"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = int(2**12)\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "batch_count = int(len(training_data)/batch_size) + 1\n",
    "batch_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:14.461913500Z",
     "start_time": "2023-08-22T18:41:14.457130600Z"
    }
   },
   "id": "bbbbe98aedcd538c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "        self.Max_Pool_2D = nn.MaxPool2d(2)\n",
    "        self.Activation = nn.GELU()\n",
    "        \n",
    "        self.conv_0 = nn.Sequential(OrderedDict([\n",
    "            (\"conv0\", nn.Conv2d(1,16,3, padding=1)),\n",
    "            (\"act0\", nn.GELU()),\n",
    "            (\"batch_norm0\", nn.BatchNorm2d(16)),\n",
    "            (\"conv1\", nn.Conv2d(16,16,3, padding=1)),\n",
    "            (\"act1\", nn.GELU()),\n",
    "            (\"batch_norm1\", nn.BatchNorm2d(16)),\n",
    "            (\"max_pool\", nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        \n",
    "        self.conv_1 = nn.Sequential(OrderedDict([\n",
    "            (\"conv0\", nn.Conv2d(16,32,3, padding=1)),\n",
    "            (\"act0\", nn.GELU()),\n",
    "            (\"batch_norm0\", nn.BatchNorm2d(32)),\n",
    "            (\"conv1\", nn.Conv2d(32,32,3, padding=1)),\n",
    "            (\"act1\", nn.GELU()),\n",
    "            (\"batch_norm1\", nn.BatchNorm2d(32)),\n",
    "            (\"max_pool\", nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        \n",
    "        self.conv_2 = nn.Sequential(OrderedDict([\n",
    "            (\"conv0\", nn.Conv2d(32,64,3, padding=1)),\n",
    "            (\"act0\", nn.GELU()),\n",
    "            (\"batch_norm0\", nn.BatchNorm2d(64)),\n",
    "            (\"conv1\", nn.Conv2d(64,64,3, padding=1)),\n",
    "            (\"act1\", nn.GELU()),\n",
    "            (\"batch_norm1\", nn.BatchNorm2d(64)),\n",
    "            (\"max_pool\", nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        \n",
    "        self.conv_3 = nn.Sequential(OrderedDict([\n",
    "            (\"conv0\", nn.Conv2d(64,128,3, padding=1)),\n",
    "            (\"act0\", nn.GELU()),\n",
    "            (\"batch_norm0\", nn.BatchNorm2d(128)),\n",
    "            (\"conv1\", nn.Conv2d(128,128,3, padding=1)),\n",
    "            (\"act1\", nn.GELU()),\n",
    "            (\"batch_norm1\", nn.BatchNorm2d(128)),\n",
    "            (\"max_pool\", nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        \n",
    "        self.linear_stack = nn.Sequential(OrderedDict([\n",
    "            (\"flatten\", nn.Flatten()),\n",
    "            (\"dropout1\", nn.Dropout(0.3)),\n",
    "            (\"linear1\", nn.Linear(2*2*128, 2048)),\n",
    "            (\"act1\", nn.GELU()),\n",
    "            (\"batch_norm1\", nn.BatchNorm1d(2048)),\n",
    "            (\"dropout2\", nn.Dropout(0.3)),\n",
    "            (\"linear2\", nn.Linear(2048, 2048)),\n",
    "            (\"act2\", nn.GELU()),\n",
    "            (\"batch_norm2\", nn.BatchNorm1d(2048)),\n",
    "            (\"linear3\", nn.Linear(2048,10)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            x = train_run_transform(x)\n",
    "        \n",
    "        x = self.conv_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.linear_stack(x)\n",
    "        \n",
    "        if self.training:\n",
    "            return x\n",
    "        else:\n",
    "            return self.Softmax(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:14.475542300Z",
     "start_time": "2023-08-22T18:41:14.461913500Z"
    }
   },
   "id": "b67d7d1fc0a9afc1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nNeuralNetwork                            [4096, 10]                --\n├─Sequential: 1-1                        [4096, 16, 16, 16]        --\n│    └─Conv2d: 2-1                       [4096, 16, 32, 32]        160\n│    └─GELU: 2-2                         [4096, 16, 32, 32]        --\n│    └─BatchNorm2d: 2-3                  [4096, 16, 32, 32]        32\n│    └─Conv2d: 2-4                       [4096, 16, 32, 32]        2,320\n│    └─GELU: 2-5                         [4096, 16, 32, 32]        --\n│    └─BatchNorm2d: 2-6                  [4096, 16, 32, 32]        32\n│    └─MaxPool2d: 2-7                    [4096, 16, 16, 16]        --\n├─Sequential: 1-2                        [4096, 32, 8, 8]          --\n│    └─Conv2d: 2-8                       [4096, 32, 16, 16]        4,640\n│    └─GELU: 2-9                         [4096, 32, 16, 16]        --\n│    └─BatchNorm2d: 2-10                 [4096, 32, 16, 16]        64\n│    └─Conv2d: 2-11                      [4096, 32, 16, 16]        9,248\n│    └─GELU: 2-12                        [4096, 32, 16, 16]        --\n│    └─BatchNorm2d: 2-13                 [4096, 32, 16, 16]        64\n│    └─MaxPool2d: 2-14                   [4096, 32, 8, 8]          --\n├─Sequential: 1-3                        [4096, 64, 4, 4]          --\n│    └─Conv2d: 2-15                      [4096, 64, 8, 8]          18,496\n│    └─GELU: 2-16                        [4096, 64, 8, 8]          --\n│    └─BatchNorm2d: 2-17                 [4096, 64, 8, 8]          128\n│    └─Conv2d: 2-18                      [4096, 64, 8, 8]          36,928\n│    └─GELU: 2-19                        [4096, 64, 8, 8]          --\n│    └─BatchNorm2d: 2-20                 [4096, 64, 8, 8]          128\n│    └─MaxPool2d: 2-21                   [4096, 64, 4, 4]          --\n├─Sequential: 1-4                        [4096, 128, 2, 2]         --\n│    └─Conv2d: 2-22                      [4096, 128, 4, 4]         73,856\n│    └─GELU: 2-23                        [4096, 128, 4, 4]         --\n│    └─BatchNorm2d: 2-24                 [4096, 128, 4, 4]         256\n│    └─Conv2d: 2-25                      [4096, 128, 4, 4]         147,584\n│    └─GELU: 2-26                        [4096, 128, 4, 4]         --\n│    └─BatchNorm2d: 2-27                 [4096, 128, 4, 4]         256\n│    └─MaxPool2d: 2-28                   [4096, 128, 2, 2]         --\n├─Sequential: 1-5                        [4096, 10]                --\n│    └─Flatten: 2-29                     [4096, 512]               --\n│    └─Dropout: 2-30                     [4096, 512]               --\n│    └─Linear: 2-31                      [4096, 2048]              1,050,624\n│    └─GELU: 2-32                        [4096, 2048]              --\n│    └─BatchNorm1d: 2-33                 [4096, 2048]              4,096\n│    └─Dropout: 2-34                     [4096, 2048]              --\n│    └─Linear: 2-35                      [4096, 2048]              4,196,352\n│    └─GELU: 2-36                        [4096, 2048]              --\n│    └─BatchNorm1d: 2-37                 [4096, 2048]              4,096\n│    └─Linear: 2-38                      [4096, 10]                20,490\n├─Softmax: 1-6                           [4096, 10]                --\n==========================================================================================\nTotal params: 5,569,850\nTrainable params: 5,569,850\nNon-trainable params: 0\nTotal mult-adds (Units.GIGABYTES): 75.62\n==========================================================================================\nInput size (MB): 16.78\nForward/backward pass size (MB): 4295.29\nParams size (MB): 22.28\nEstimated Total Size (MB): 4334.35\n=========================================================================================="
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "summary(model, input_size=(batch_size, 1, 32, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:16.855001600Z",
     "start_time": "2023-08-22T18:41:14.475542300Z"
    }
   },
   "id": "dbf8b68af22b4a1c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "run_comment = input(\"Run Comment: \")\n",
    "writer = SummaryWriter(comment=\" \" + run_comment)\n",
    "writer.add_scalar(\"Loss/Train\", 1.0, 0)\n",
    "writer.add_scalar(\"Accuracy/Test\", 0, 0)\n",
    "writer.add_scalar(\"Accuracy/Train\", 0, 0)\n",
    "epoch_count = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T18:41:25.029622Z",
     "start_time": "2023-08-22T18:41:16.855001600Z"
    }
   },
   "id": "891ac39be80adce9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     7] loss: 6.616\n",
      "[1,    14] loss: 2.733\n",
      "[1,    21] loss: 1.766\n",
      "[1,    28] loss: 1.185\n",
      "[1,    35] loss: 0.859\n",
      "[1,    42] loss: 0.654\n",
      "[1,    49] loss: 0.644\n",
      "[1,    56] loss: 0.518\n",
      "[2,     7] loss: 0.384\n",
      "[2,    14] loss: 0.342\n",
      "[2,    21] loss: 0.261\n",
      "[2,    28] loss: 0.261\n",
      "[2,    35] loss: 0.257\n",
      "[2,    42] loss: 0.226\n",
      "[2,    49] loss: 0.152\n",
      "[2,    56] loss: 0.132\n",
      "[3,     7] loss: 0.118\n",
      "[3,    14] loss: 0.118\n",
      "[3,    21] loss: 0.130\n",
      "[3,    28] loss: 0.123\n",
      "[3,    35] loss: 0.118\n",
      "[3,    42] loss: 0.120\n",
      "[3,    49] loss: 0.120\n",
      "[3,    56] loss: 0.098\n",
      "[4,     7] loss: 0.101\n",
      "[4,    14] loss: 0.089\n",
      "[4,    21] loss: 0.078\n",
      "[4,    28] loss: 0.073\n",
      "[4,    35] loss: 0.070\n",
      "[4,    42] loss: 0.085\n",
      "[4,    49] loss: 0.063\n",
      "[4,    56] loss: 0.071\n",
      "[5,     7] loss: 0.059\n",
      "[5,    14] loss: 0.064\n",
      "[5,    21] loss: 0.068\n",
      "[5,    28] loss: 0.066\n",
      "[5,    35] loss: 0.062\n",
      "[5,    42] loss: 0.064\n",
      "[5,    49] loss: 0.052\n",
      "[5,    56] loss: 0.052\n",
      "[6,     7] loss: 0.060\n",
      "[6,    14] loss: 0.049\n",
      "[6,    21] loss: 0.050\n",
      "[6,    28] loss: 0.051\n",
      "[6,    35] loss: 0.046\n",
      "[6,    42] loss: 0.042\n",
      "[6,    49] loss: 0.050\n",
      "[6,    56] loss: 0.048\n",
      "[7,     7] loss: 0.051\n",
      "[7,    14] loss: 0.038\n",
      "[7,    21] loss: 0.045\n",
      "[7,    28] loss: 0.044\n",
      "[7,    35] loss: 0.048\n",
      "[7,    42] loss: 0.044\n",
      "[7,    49] loss: 0.046\n",
      "[7,    56] loss: 0.039\n",
      "[8,     7] loss: 0.039\n",
      "[8,    14] loss: 0.035\n",
      "[8,    21] loss: 0.043\n",
      "[8,    28] loss: 0.033\n",
      "[8,    35] loss: 0.035\n",
      "[8,    42] loss: 0.039\n",
      "[8,    49] loss: 0.030\n",
      "[8,    56] loss: 0.040\n",
      "[9,     7] loss: 0.035\n",
      "[9,    14] loss: 0.048\n",
      "[9,    21] loss: 0.034\n",
      "[9,    28] loss: 0.044\n",
      "[9,    35] loss: 0.042\n",
      "[9,    42] loss: 0.044\n",
      "[9,    49] loss: 0.036\n",
      "[9,    56] loss: 0.033\n",
      "[10,     7] loss: 0.031\n",
      "[10,    14] loss: 0.034\n",
      "[10,    21] loss: 0.036\n",
      "[10,    28] loss: 0.032\n",
      "[10,    35] loss: 0.032\n",
      "[10,    42] loss: 0.029\n",
      "[10,    49] loss: 0.027\n",
      "[10,    56] loss: 0.027\n",
      "[11,     7] loss: 0.025\n",
      "[11,    14] loss: 0.033\n",
      "[11,    21] loss: 0.028\n",
      "[11,    28] loss: 0.033\n",
      "[11,    35] loss: 0.027\n",
      "[11,    42] loss: 0.027\n",
      "[11,    49] loss: 0.033\n",
      "[11,    56] loss: 0.029\n",
      "[12,     7] loss: 0.029\n",
      "[12,    14] loss: 0.030\n",
      "[12,    21] loss: 0.031\n",
      "[12,    28] loss: 0.026\n",
      "[12,    35] loss: 0.024\n",
      "[12,    42] loss: 0.025\n",
      "[12,    49] loss: 0.027\n",
      "[12,    56] loss: 0.026\n",
      "[13,     7] loss: 0.026\n",
      "[13,    14] loss: 0.026\n",
      "[13,    21] loss: 0.023\n",
      "[13,    28] loss: 0.027\n",
      "[13,    35] loss: 0.026\n",
      "[13,    42] loss: 0.031\n",
      "[13,    49] loss: 0.036\n",
      "[13,    56] loss: 0.029\n",
      "[14,     7] loss: 0.024\n",
      "[14,    14] loss: 0.023\n",
      "[14,    21] loss: 0.023\n",
      "[14,    28] loss: 0.020\n",
      "[14,    35] loss: 0.025\n",
      "[14,    42] loss: 0.023\n",
      "[14,    49] loss: 0.023\n",
      "[14,    56] loss: 0.029\n",
      "[15,     7] loss: 0.023\n",
      "[15,    14] loss: 0.023\n",
      "[15,    21] loss: 0.028\n",
      "[15,    28] loss: 0.025\n",
      "[15,    35] loss: 0.029\n",
      "[15,    42] loss: 0.024\n",
      "[15,    49] loss: 0.022\n",
      "[15,    56] loss: 0.024\n",
      "[16,     7] loss: 0.029\n",
      "[16,    14] loss: 0.022\n",
      "[16,    21] loss: 0.019\n",
      "[16,    28] loss: 0.026\n",
      "[16,    35] loss: 0.023\n",
      "[16,    42] loss: 0.023\n",
      "[16,    49] loss: 0.019\n",
      "[16,    56] loss: 0.017\n",
      "[17,     7] loss: 0.019\n",
      "[17,    14] loss: 0.018\n",
      "[17,    21] loss: 0.022\n",
      "[17,    28] loss: 0.023\n",
      "[17,    35] loss: 0.021\n",
      "[17,    42] loss: 0.024\n",
      "[17,    49] loss: 0.022\n",
      "[17,    56] loss: 0.027\n",
      "[18,     7] loss: 0.021\n",
      "[18,    14] loss: 0.024\n",
      "[18,    21] loss: 0.020\n",
      "[18,    28] loss: 0.022\n",
      "[18,    35] loss: 0.020\n",
      "[18,    42] loss: 0.021\n",
      "[18,    49] loss: 0.022\n",
      "[18,    56] loss: 0.025\n",
      "[19,     7] loss: 0.023\n",
      "[19,    14] loss: 0.019\n",
      "[19,    21] loss: 0.022\n",
      "[19,    28] loss: 0.016\n",
      "[19,    35] loss: 0.021\n",
      "[19,    42] loss: 0.019\n",
      "[19,    49] loss: 0.018\n",
      "[19,    56] loss: 0.020\n",
      "[20,     7] loss: 0.019\n",
      "[20,    14] loss: 0.021\n",
      "[20,    21] loss: 0.020\n",
      "[20,    28] loss: 0.022\n",
      "[20,    35] loss: 0.017\n",
      "[20,    42] loss: 0.018\n",
      "[20,    49] loss: 0.017\n",
      "[20,    56] loss: 0.017\n",
      "[21,     7] loss: 0.021\n",
      "[21,    14] loss: 0.018\n",
      "[21,    21] loss: 0.021\n",
      "[21,    28] loss: 0.025\n",
      "[21,    35] loss: 0.022\n",
      "[21,    42] loss: 0.019\n",
      "[21,    49] loss: 0.020\n",
      "[21,    56] loss: 0.019\n",
      "[22,     7] loss: 0.016\n",
      "[22,    14] loss: 0.019\n",
      "[22,    21] loss: 0.016\n",
      "[22,    28] loss: 0.020\n",
      "[22,    35] loss: 0.018\n",
      "[22,    42] loss: 0.022\n",
      "[22,    49] loss: 0.024\n",
      "[22,    56] loss: 0.023\n",
      "[23,     7] loss: 0.019\n",
      "[23,    14] loss: 0.018\n",
      "[23,    21] loss: 0.016\n",
      "[23,    28] loss: 0.017\n",
      "[23,    35] loss: 0.019\n",
      "[23,    42] loss: 0.019\n",
      "[23,    49] loss: 0.015\n",
      "[23,    56] loss: 0.016\n",
      "[24,     7] loss: 0.019\n",
      "[24,    14] loss: 0.015\n",
      "[24,    21] loss: 0.019\n",
      "[24,    28] loss: 0.018\n",
      "[24,    35] loss: 0.018\n",
      "[24,    42] loss: 0.017\n",
      "[24,    49] loss: 0.019\n",
      "[24,    56] loss: 0.019\n",
      "[25,     7] loss: 0.019\n",
      "[25,    14] loss: 0.018\n",
      "[25,    21] loss: 0.020\n",
      "[25,    28] loss: 0.019\n",
      "[25,    35] loss: 0.018\n",
      "[25,    42] loss: 0.015\n",
      "[25,    49] loss: 0.017\n",
      "[25,    56] loss: 0.021\n",
      "[26,     7] loss: 0.018\n",
      "[26,    14] loss: 0.018\n",
      "[26,    21] loss: 0.015\n",
      "[26,    28] loss: 0.014\n",
      "[26,    35] loss: 0.017\n",
      "[26,    42] loss: 0.017\n",
      "[26,    49] loss: 0.018\n",
      "[26,    56] loss: 0.017\n",
      "[27,     7] loss: 0.013\n",
      "[27,    14] loss: 0.019\n",
      "[27,    21] loss: 0.018\n",
      "[27,    28] loss: 0.017\n",
      "[27,    35] loss: 0.016\n",
      "[27,    42] loss: 0.018\n",
      "[27,    49] loss: 0.016\n",
      "[27,    56] loss: 0.017\n",
      "[28,     7] loss: 0.016\n",
      "[28,    14] loss: 0.014\n",
      "[28,    21] loss: 0.015\n",
      "[28,    28] loss: 0.015\n",
      "[28,    35] loss: 0.017\n",
      "[28,    42] loss: 0.017\n",
      "[28,    49] loss: 0.021\n",
      "[28,    56] loss: 0.017\n",
      "[29,     7] loss: 0.018\n",
      "[29,    14] loss: 0.019\n",
      "[29,    21] loss: 0.015\n",
      "[29,    28] loss: 0.016\n",
      "[29,    35] loss: 0.016\n",
      "[29,    42] loss: 0.015\n",
      "[29,    49] loss: 0.016\n",
      "[29,    56] loss: 0.016\n",
      "[30,     7] loss: 0.016\n",
      "[30,    14] loss: 0.017\n",
      "[30,    21] loss: 0.016\n",
      "[30,    28] loss: 0.018\n",
      "[30,    35] loss: 0.015\n",
      "[30,    42] loss: 0.016\n",
      "[30,    49] loss: 0.017\n",
      "[30,    56] loss: 0.018\n",
      "[31,     7] loss: 0.016\n",
      "[31,    14] loss: 0.017\n",
      "[31,    21] loss: 0.015\n",
      "[31,    28] loss: 0.017\n",
      "[31,    35] loss: 0.016\n",
      "[31,    42] loss: 0.015\n",
      "[31,    49] loss: 0.015\n",
      "[31,    56] loss: 0.018\n",
      "[32,     7] loss: 0.018\n",
      "[32,    14] loss: 0.017\n",
      "[32,    21] loss: 0.017\n",
      "[32,    28] loss: 0.017\n",
      "[32,    35] loss: 0.016\n",
      "[32,    42] loss: 0.017\n",
      "[32,    49] loss: 0.017\n",
      "[32,    56] loss: 0.017\n",
      "[33,     7] loss: 0.016\n",
      "[33,    14] loss: 0.016\n",
      "[33,    21] loss: 0.014\n",
      "[33,    28] loss: 0.013\n",
      "[33,    35] loss: 0.013\n",
      "[33,    42] loss: 0.015\n",
      "[33,    49] loss: 0.017\n",
      "[33,    56] loss: 0.015\n",
      "[34,     7] loss: 0.012\n",
      "[34,    14] loss: 0.012\n",
      "[34,    21] loss: 0.015\n",
      "[34,    28] loss: 0.014\n",
      "[34,    35] loss: 0.013\n",
      "[34,    42] loss: 0.014\n",
      "[34,    49] loss: 0.014\n",
      "[34,    56] loss: 0.016\n",
      "[35,     7] loss: 0.014\n",
      "[35,    14] loss: 0.017\n",
      "[35,    21] loss: 0.015\n",
      "[35,    28] loss: 0.015\n",
      "[35,    35] loss: 0.017\n",
      "[35,    42] loss: 0.014\n",
      "[35,    49] loss: 0.014\n",
      "[35,    56] loss: 0.015\n",
      "[36,     7] loss: 0.015\n",
      "[36,    14] loss: 0.018\n",
      "[36,    21] loss: 0.017\n",
      "[36,    28] loss: 0.012\n",
      "[36,    35] loss: 0.014\n",
      "[36,    42] loss: 0.013\n",
      "[36,    49] loss: 0.011\n",
      "[36,    56] loss: 0.013\n",
      "[37,     7] loss: 0.013\n",
      "[37,    14] loss: 0.015\n",
      "[37,    21] loss: 0.014\n",
      "[37,    28] loss: 0.015\n",
      "[37,    35] loss: 0.015\n",
      "[37,    42] loss: 0.014\n",
      "[37,    49] loss: 0.017\n",
      "[37,    56] loss: 0.021\n",
      "[38,     7] loss: 0.015\n",
      "[38,    14] loss: 0.018\n",
      "[38,    21] loss: 0.017\n",
      "[38,    28] loss: 0.012\n",
      "[38,    35] loss: 0.016\n",
      "[38,    42] loss: 0.011\n",
      "[38,    49] loss: 0.013\n",
      "[38,    56] loss: 0.014\n",
      "[39,     7] loss: 0.015\n",
      "[39,    14] loss: 0.014\n",
      "[39,    21] loss: 0.016\n",
      "[39,    28] loss: 0.013\n",
      "[39,    35] loss: 0.014\n",
      "[39,    42] loss: 0.011\n",
      "[39,    49] loss: 0.014\n",
      "[39,    56] loss: 0.016\n",
      "[40,     7] loss: 0.013\n",
      "[40,    14] loss: 0.014\n",
      "[40,    21] loss: 0.015\n",
      "[40,    28] loss: 0.021\n",
      "[40,    35] loss: 0.016\n",
      "[40,    42] loss: 0.017\n",
      "[40,    49] loss: 0.011\n",
      "[40,    56] loss: 0.012\n",
      "[41,     7] loss: 0.013\n",
      "[41,    14] loss: 0.013\n",
      "[41,    21] loss: 0.014\n",
      "[41,    28] loss: 0.014\n",
      "[41,    35] loss: 0.015\n",
      "[41,    42] loss: 0.013\n",
      "[41,    49] loss: 0.013\n",
      "[41,    56] loss: 0.015\n",
      "[42,     7] loss: 0.011\n",
      "[42,    14] loss: 0.014\n",
      "[42,    21] loss: 0.014\n",
      "[42,    28] loss: 0.017\n",
      "[42,    35] loss: 0.013\n",
      "[42,    42] loss: 0.017\n",
      "[42,    49] loss: 0.013\n",
      "[42,    56] loss: 0.012\n",
      "[43,     7] loss: 0.014\n",
      "[43,    14] loss: 0.013\n",
      "[43,    21] loss: 0.013\n",
      "[43,    28] loss: 0.014\n",
      "[43,    35] loss: 0.012\n",
      "[43,    42] loss: 0.013\n",
      "[43,    49] loss: 0.011\n",
      "[43,    56] loss: 0.015\n",
      "[44,     7] loss: 0.013\n",
      "[44,    14] loss: 0.016\n",
      "[44,    21] loss: 0.016\n",
      "[44,    28] loss: 0.015\n",
      "[44,    35] loss: 0.017\n",
      "[44,    42] loss: 0.018\n",
      "[44,    49] loss: 0.016\n",
      "[44,    56] loss: 0.013\n",
      "[45,     7] loss: 0.016\n",
      "[45,    14] loss: 0.012\n",
      "[45,    21] loss: 0.012\n",
      "[45,    28] loss: 0.014\n",
      "[45,    35] loss: 0.017\n",
      "[45,    42] loss: 0.015\n",
      "[45,    49] loss: 0.015\n",
      "[45,    56] loss: 0.013\n",
      "[46,     7] loss: 0.012\n",
      "[46,    14] loss: 0.013\n",
      "[46,    21] loss: 0.013\n",
      "[46,    28] loss: 0.015\n",
      "[46,    35] loss: 0.014\n",
      "[46,    42] loss: 0.012\n",
      "[46,    49] loss: 0.019\n",
      "[46,    56] loss: 0.016\n",
      "[47,     7] loss: 0.012\n",
      "[47,    14] loss: 0.012\n",
      "[47,    21] loss: 0.012\n",
      "[47,    28] loss: 0.013\n",
      "[47,    35] loss: 0.010\n",
      "[47,    42] loss: 0.013\n",
      "[47,    49] loss: 0.016\n",
      "[47,    56] loss: 0.013\n",
      "[48,     7] loss: 0.014\n",
      "[48,    14] loss: 0.009\n",
      "[48,    21] loss: 0.018\n",
      "[48,    28] loss: 0.016\n",
      "[48,    35] loss: 0.015\n",
      "[48,    42] loss: 0.014\n",
      "[48,    49] loss: 0.013\n",
      "[48,    56] loss: 0.015\n",
      "[49,     7] loss: 0.013\n",
      "[49,    14] loss: 0.016\n",
      "[49,    21] loss: 0.013\n",
      "[49,    28] loss: 0.011\n",
      "[49,    35] loss: 0.012\n",
      "[49,    42] loss: 0.013\n",
      "[49,    49] loss: 0.012\n",
      "[49,    56] loss: 0.014\n",
      "[50,     7] loss: 0.014\n",
      "[50,    14] loss: 0.011\n",
      "[50,    21] loss: 0.011\n",
      "[50,    28] loss: 0.015\n",
      "[50,    35] loss: 0.014\n",
      "[50,    42] loss: 0.014\n",
      "[50,    49] loss: 0.012\n",
      "[50,    56] loss: 0.016\n",
      "[51,     7] loss: 0.012\n",
      "[51,    14] loss: 0.013\n",
      "[51,    21] loss: 0.012\n",
      "[51,    28] loss: 0.016\n",
      "[51,    35] loss: 0.012\n",
      "[51,    42] loss: 0.012\n",
      "[51,    49] loss: 0.014\n",
      "[51,    56] loss: 0.013\n",
      "[52,     7] loss: 0.010\n",
      "[52,    14] loss: 0.014\n",
      "[52,    21] loss: 0.013\n",
      "[52,    28] loss: 0.015\n",
      "[52,    35] loss: 0.014\n",
      "[52,    42] loss: 0.012\n",
      "[52,    49] loss: 0.014\n",
      "[52,    56] loss: 0.014\n",
      "[53,     7] loss: 0.014\n",
      "[53,    14] loss: 0.013\n",
      "[53,    21] loss: 0.014\n",
      "[53,    28] loss: 0.012\n",
      "[53,    35] loss: 0.012\n",
      "[53,    42] loss: 0.013\n",
      "[53,    49] loss: 0.013\n",
      "[53,    56] loss: 0.012\n",
      "[54,     7] loss: 0.013\n",
      "[54,    14] loss: 0.011\n",
      "[54,    21] loss: 0.014\n",
      "[54,    28] loss: 0.012\n",
      "[54,    35] loss: 0.013\n",
      "[54,    42] loss: 0.012\n",
      "[54,    49] loss: 0.012\n",
      "[54,    56] loss: 0.011\n",
      "[55,     7] loss: 0.012\n",
      "[55,    14] loss: 0.015\n",
      "[55,    21] loss: 0.013\n",
      "[55,    28] loss: 0.011\n",
      "[55,    35] loss: 0.013\n",
      "[55,    42] loss: 0.013\n",
      "[55,    49] loss: 0.013\n",
      "[55,    56] loss: 0.012\n",
      "[56,     7] loss: 0.014\n",
      "[56,    14] loss: 0.015\n",
      "[56,    21] loss: 0.014\n",
      "[56,    28] loss: 0.013\n",
      "[56,    35] loss: 0.011\n",
      "[56,    42] loss: 0.012\n",
      "[56,    49] loss: 0.011\n",
      "[56,    56] loss: 0.012\n",
      "[57,     7] loss: 0.012\n",
      "[57,    14] loss: 0.013\n",
      "[57,    21] loss: 0.011\n",
      "[57,    28] loss: 0.015\n",
      "[57,    35] loss: 0.013\n",
      "[57,    42] loss: 0.010\n",
      "[57,    49] loss: 0.014\n",
      "[57,    56] loss: 0.012\n",
      "[58,     7] loss: 0.014\n",
      "[58,    14] loss: 0.011\n",
      "[58,    21] loss: 0.013\n",
      "[58,    28] loss: 0.010\n",
      "[58,    35] loss: 0.011\n",
      "[58,    42] loss: 0.012\n",
      "[58,    49] loss: 0.011\n",
      "[58,    56] loss: 0.012\n",
      "[59,     7] loss: 0.011\n",
      "[59,    14] loss: 0.011\n",
      "[59,    21] loss: 0.012\n",
      "[59,    28] loss: 0.012\n",
      "[59,    35] loss: 0.013\n",
      "[59,    42] loss: 0.013\n",
      "[59,    49] loss: 0.010\n",
      "[59,    56] loss: 0.012\n",
      "[60,     7] loss: 0.009\n",
      "[60,    14] loss: 0.011\n",
      "[60,    21] loss: 0.012\n",
      "[60,    28] loss: 0.016\n",
      "[60,    35] loss: 0.012\n",
      "[60,    42] loss: 0.012\n",
      "[60,    49] loss: 0.013\n",
      "[60,    56] loss: 0.013\n",
      "[61,     7] loss: 0.015\n",
      "[61,    14] loss: 0.012\n",
      "[61,    21] loss: 0.013\n",
      "[61,    28] loss: 0.013\n",
      "[61,    35] loss: 0.010\n",
      "[61,    42] loss: 0.013\n",
      "[61,    49] loss: 0.015\n",
      "[61,    56] loss: 0.012\n",
      "[62,     7] loss: 0.011\n",
      "[62,    14] loss: 0.011\n",
      "[62,    21] loss: 0.012\n",
      "[62,    28] loss: 0.015\n",
      "[62,    35] loss: 0.011\n",
      "[62,    42] loss: 0.012\n",
      "[62,    49] loss: 0.011\n",
      "[62,    56] loss: 0.014\n",
      "[63,     7] loss: 0.011\n",
      "[63,    14] loss: 0.010\n",
      "[63,    21] loss: 0.012\n",
      "[63,    28] loss: 0.012\n",
      "[63,    35] loss: 0.015\n",
      "[63,    42] loss: 0.014\n",
      "[63,    49] loss: 0.012\n",
      "[63,    56] loss: 0.016\n",
      "[64,     7] loss: 0.012\n",
      "[64,    14] loss: 0.011\n",
      "[64,    21] loss: 0.014\n",
      "[64,    28] loss: 0.013\n",
      "[64,    35] loss: 0.014\n",
      "[64,    42] loss: 0.015\n",
      "[64,    49] loss: 0.013\n",
      "[64,    56] loss: 0.014\n",
      "[65,     7] loss: 0.013\n",
      "[65,    14] loss: 0.010\n",
      "[65,    21] loss: 0.015\n",
      "[65,    28] loss: 0.010\n",
      "[65,    35] loss: 0.015\n",
      "[65,    42] loss: 0.015\n",
      "[65,    49] loss: 0.014\n",
      "[65,    56] loss: 0.012\n",
      "[66,     7] loss: 0.011\n",
      "[66,    14] loss: 0.011\n",
      "[66,    21] loss: 0.011\n",
      "[66,    28] loss: 0.010\n",
      "[66,    35] loss: 0.012\n",
      "[66,    42] loss: 0.014\n",
      "[66,    49] loss: 0.013\n",
      "[66,    56] loss: 0.013\n",
      "[67,     7] loss: 0.012\n",
      "[67,    14] loss: 0.016\n",
      "[67,    21] loss: 0.013\n",
      "[67,    28] loss: 0.013\n",
      "[67,    35] loss: 0.012\n",
      "[67,    42] loss: 0.009\n",
      "[67,    49] loss: 0.011\n",
      "[67,    56] loss: 0.013\n",
      "[68,     7] loss: 0.011\n",
      "[68,    14] loss: 0.012\n",
      "[68,    21] loss: 0.011\n",
      "[68,    28] loss: 0.013\n",
      "[68,    35] loss: 0.010\n",
      "[68,    42] loss: 0.011\n",
      "[68,    49] loss: 0.012\n",
      "[68,    56] loss: 0.010\n",
      "[69,     7] loss: 0.011\n",
      "[69,    14] loss: 0.011\n",
      "[69,    21] loss: 0.010\n",
      "[69,    28] loss: 0.015\n",
      "[69,    35] loss: 0.011\n",
      "[69,    42] loss: 0.010\n",
      "[69,    49] loss: 0.012\n",
      "[69,    56] loss: 0.011\n",
      "[70,     7] loss: 0.012\n",
      "[70,    14] loss: 0.011\n",
      "[70,    21] loss: 0.010\n",
      "[70,    28] loss: 0.010\n",
      "[70,    35] loss: 0.010\n",
      "[70,    42] loss: 0.011\n",
      "[70,    49] loss: 0.013\n",
      "[70,    56] loss: 0.011\n",
      "[71,     7] loss: 0.012\n",
      "[71,    14] loss: 0.011\n",
      "[71,    21] loss: 0.013\n",
      "[71,    28] loss: 0.010\n",
      "[71,    35] loss: 0.011\n",
      "[71,    42] loss: 0.010\n",
      "[71,    49] loss: 0.012\n",
      "[71,    56] loss: 0.012\n",
      "[72,     7] loss: 0.011\n",
      "[72,    14] loss: 0.011\n",
      "[72,    21] loss: 0.010\n",
      "[72,    28] loss: 0.010\n",
      "[72,    35] loss: 0.013\n",
      "[72,    42] loss: 0.013\n",
      "[72,    49] loss: 0.012\n",
      "[72,    56] loss: 0.011\n",
      "[73,     7] loss: 0.013\n",
      "[73,    14] loss: 0.011\n",
      "[73,    21] loss: 0.009\n",
      "[73,    28] loss: 0.010\n",
      "[73,    35] loss: 0.010\n",
      "[73,    42] loss: 0.012\n",
      "[73,    49] loss: 0.011\n",
      "[73,    56] loss: 0.009\n",
      "[74,     7] loss: 0.009\n",
      "[74,    14] loss: 0.009\n",
      "[74,    21] loss: 0.012\n",
      "[74,    28] loss: 0.011\n",
      "[74,    35] loss: 0.010\n",
      "[74,    42] loss: 0.009\n",
      "[74,    49] loss: 0.009\n",
      "[74,    56] loss: 0.013\n",
      "[75,     7] loss: 0.012\n",
      "[75,    14] loss: 0.011\n",
      "[75,    21] loss: 0.015\n",
      "[75,    28] loss: 0.012\n",
      "[75,    35] loss: 0.011\n",
      "[75,    42] loss: 0.010\n",
      "[75,    49] loss: 0.012\n",
      "[75,    56] loss: 0.011\n",
      "[76,     7] loss: 0.012\n",
      "[76,    14] loss: 0.008\n",
      "[76,    21] loss: 0.012\n",
      "[76,    28] loss: 0.010\n",
      "[76,    35] loss: 0.010\n",
      "[76,    42] loss: 0.011\n",
      "[76,    49] loss: 0.012\n",
      "[76,    56] loss: 0.011\n",
      "[77,     7] loss: 0.009\n",
      "[77,    14] loss: 0.009\n",
      "[77,    21] loss: 0.009\n",
      "[77,    28] loss: 0.012\n",
      "[77,    35] loss: 0.011\n",
      "[77,    42] loss: 0.010\n",
      "[77,    49] loss: 0.012\n",
      "[77,    56] loss: 0.012\n",
      "[78,     7] loss: 0.009\n",
      "[78,    14] loss: 0.011\n",
      "[78,    21] loss: 0.010\n",
      "[78,    28] loss: 0.012\n",
      "[78,    35] loss: 0.010\n",
      "[78,    42] loss: 0.012\n",
      "[78,    49] loss: 0.012\n",
      "[78,    56] loss: 0.011\n",
      "[79,     7] loss: 0.012\n",
      "[79,    14] loss: 0.009\n",
      "[79,    21] loss: 0.011\n",
      "[79,    28] loss: 0.010\n",
      "[79,    35] loss: 0.010\n",
      "[79,    42] loss: 0.010\n",
      "[79,    49] loss: 0.012\n",
      "[79,    56] loss: 0.013\n",
      "[80,     7] loss: 0.010\n",
      "[80,    14] loss: 0.012\n",
      "[80,    21] loss: 0.010\n",
      "[80,    28] loss: 0.009\n",
      "[80,    35] loss: 0.012\n",
      "[80,    42] loss: 0.011\n",
      "[80,    49] loss: 0.011\n",
      "[80,    56] loss: 0.014\n",
      "[81,     7] loss: 0.010\n",
      "[81,    14] loss: 0.011\n",
      "[81,    21] loss: 0.011\n",
      "[81,    28] loss: 0.014\n",
      "[81,    35] loss: 0.016\n",
      "[81,    42] loss: 0.013\n",
      "[81,    49] loss: 0.012\n",
      "[81,    56] loss: 0.012\n",
      "[82,     7] loss: 0.012\n",
      "[82,    14] loss: 0.013\n",
      "[82,    21] loss: 0.013\n",
      "[82,    28] loss: 0.011\n",
      "[82,    35] loss: 0.010\n",
      "[82,    42] loss: 0.009\n",
      "[82,    49] loss: 0.012\n",
      "[82,    56] loss: 0.011\n",
      "[83,     7] loss: 0.009\n",
      "[83,    14] loss: 0.011\n",
      "[83,    21] loss: 0.010\n",
      "[83,    28] loss: 0.010\n",
      "[83,    35] loss: 0.008\n",
      "[83,    42] loss: 0.012\n",
      "[83,    49] loss: 0.012\n",
      "[83,    56] loss: 0.012\n",
      "[84,     7] loss: 0.009\n",
      "[84,    14] loss: 0.014\n",
      "[84,    21] loss: 0.011\n",
      "[84,    28] loss: 0.008\n",
      "[84,    35] loss: 0.012\n",
      "[84,    42] loss: 0.011\n",
      "[84,    49] loss: 0.009\n",
      "[84,    56] loss: 0.010\n",
      "[85,     7] loss: 0.009\n",
      "[85,    14] loss: 0.010\n",
      "[85,    21] loss: 0.011\n",
      "[85,    28] loss: 0.011\n",
      "[85,    35] loss: 0.010\n",
      "[85,    42] loss: 0.010\n",
      "[85,    49] loss: 0.010\n",
      "[85,    56] loss: 0.010\n",
      "[86,     7] loss: 0.010\n",
      "[86,    14] loss: 0.009\n",
      "[86,    21] loss: 0.010\n",
      "[86,    28] loss: 0.011\n",
      "[86,    35] loss: 0.011\n",
      "[86,    42] loss: 0.013\n",
      "[86,    49] loss: 0.012\n",
      "[86,    56] loss: 0.010\n",
      "[87,     7] loss: 0.010\n",
      "[87,    14] loss: 0.010\n",
      "[87,    21] loss: 0.009\n",
      "[87,    28] loss: 0.010\n",
      "[87,    35] loss: 0.011\n",
      "[87,    42] loss: 0.011\n",
      "[87,    49] loss: 0.012\n",
      "[87,    56] loss: 0.011\n",
      "[88,     7] loss: 0.012\n",
      "[88,    14] loss: 0.013\n",
      "[88,    21] loss: 0.010\n",
      "[88,    28] loss: 0.010\n",
      "[88,    35] loss: 0.010\n",
      "[88,    42] loss: 0.008\n",
      "[88,    49] loss: 0.013\n",
      "[88,    56] loss: 0.010\n",
      "[89,     7] loss: 0.011\n",
      "[89,    14] loss: 0.011\n",
      "[89,    21] loss: 0.010\n",
      "[89,    28] loss: 0.007\n",
      "[89,    35] loss: 0.011\n",
      "[89,    42] loss: 0.009\n",
      "[89,    49] loss: 0.008\n",
      "[89,    56] loss: 0.012\n",
      "[90,     7] loss: 0.010\n",
      "[90,    14] loss: 0.012\n",
      "[90,    21] loss: 0.012\n",
      "[90,    28] loss: 0.010\n",
      "[90,    35] loss: 0.011\n",
      "[90,    42] loss: 0.010\n",
      "[90,    49] loss: 0.009\n",
      "[90,    56] loss: 0.010\n",
      "[91,     7] loss: 0.009\n",
      "[91,    14] loss: 0.010\n",
      "[91,    21] loss: 0.010\n",
      "[91,    28] loss: 0.008\n",
      "[91,    35] loss: 0.009\n",
      "[91,    42] loss: 0.011\n",
      "[91,    49] loss: 0.010\n",
      "[91,    56] loss: 0.010\n",
      "[92,     7] loss: 0.010\n",
      "[92,    14] loss: 0.011\n",
      "[92,    21] loss: 0.011\n",
      "[92,    28] loss: 0.012\n",
      "[92,    35] loss: 0.011\n",
      "[92,    42] loss: 0.013\n",
      "[92,    49] loss: 0.011\n",
      "[92,    56] loss: 0.014\n",
      "[93,     7] loss: 0.011\n",
      "[93,    14] loss: 0.008\n",
      "[93,    21] loss: 0.010\n",
      "[93,    28] loss: 0.009\n",
      "[93,    35] loss: 0.009\n",
      "[93,    42] loss: 0.010\n",
      "[93,    49] loss: 0.010\n",
      "[93,    56] loss: 0.010\n",
      "[94,     7] loss: 0.010\n",
      "[94,    14] loss: 0.011\n",
      "[94,    21] loss: 0.010\n",
      "[94,    28] loss: 0.009\n",
      "[94,    35] loss: 0.013\n",
      "[94,    42] loss: 0.010\n",
      "[94,    49] loss: 0.010\n",
      "[94,    56] loss: 0.011\n",
      "[95,     7] loss: 0.008\n",
      "[95,    14] loss: 0.010\n",
      "[95,    21] loss: 0.012\n",
      "[95,    28] loss: 0.010\n",
      "[95,    35] loss: 0.011\n",
      "[95,    42] loss: 0.009\n",
      "[95,    49] loss: 0.013\n",
      "[95,    56] loss: 0.010\n",
      "[96,     7] loss: 0.008\n",
      "[96,    14] loss: 0.011\n",
      "[96,    21] loss: 0.011\n",
      "[96,    28] loss: 0.009\n",
      "[96,    35] loss: 0.009\n",
      "[96,    42] loss: 0.010\n",
      "[96,    49] loss: 0.009\n",
      "[96,    56] loss: 0.012\n",
      "[97,     7] loss: 0.009\n",
      "[97,    14] loss: 0.008\n",
      "[97,    21] loss: 0.012\n",
      "[97,    28] loss: 0.008\n",
      "[97,    35] loss: 0.010\n",
      "[97,    42] loss: 0.011\n",
      "[97,    49] loss: 0.012\n",
      "[97,    56] loss: 0.009\n",
      "[98,     7] loss: 0.008\n",
      "[98,    14] loss: 0.010\n",
      "[98,    21] loss: 0.009\n",
      "[98,    28] loss: 0.011\n",
      "[98,    35] loss: 0.010\n",
      "[98,    42] loss: 0.007\n",
      "[98,    49] loss: 0.008\n",
      "[98,    56] loss: 0.012\n",
      "[99,     7] loss: 0.009\n",
      "[99,    14] loss: 0.013\n",
      "[99,    21] loss: 0.009\n",
      "[99,    28] loss: 0.009\n",
      "[99,    35] loss: 0.009\n",
      "[99,    42] loss: 0.011\n",
      "[99,    49] loss: 0.009\n",
      "[99,    56] loss: 0.009\n",
      "[100,     7] loss: 0.010\n",
      "[100,    14] loss: 0.009\n",
      "[100,    21] loss: 0.008\n",
      "[100,    28] loss: 0.009\n",
      "[100,    35] loss: 0.011\n",
      "[100,    42] loss: 0.008\n",
      "[100,    49] loss: 0.007\n",
      "[100,    56] loss: 0.009\n",
      "[101,     7] loss: 0.009\n",
      "[101,    14] loss: 0.008\n",
      "[101,    21] loss: 0.009\n",
      "[101,    28] loss: 0.010\n",
      "[101,    35] loss: 0.008\n",
      "[101,    42] loss: 0.009\n",
      "[101,    49] loss: 0.010\n",
      "[101,    56] loss: 0.010\n",
      "[102,     7] loss: 0.010\n",
      "[102,    14] loss: 0.008\n",
      "[102,    21] loss: 0.010\n",
      "[102,    28] loss: 0.007\n",
      "[102,    35] loss: 0.011\n",
      "[102,    42] loss: 0.007\n",
      "[102,    49] loss: 0.012\n",
      "[102,    56] loss: 0.012\n",
      "[103,     7] loss: 0.010\n",
      "[103,    14] loss: 0.008\n",
      "[103,    21] loss: 0.008\n",
      "[103,    28] loss: 0.011\n",
      "[103,    35] loss: 0.011\n",
      "[103,    42] loss: 0.010\n",
      "[103,    49] loss: 0.012\n",
      "[103,    56] loss: 0.011\n",
      "[104,     7] loss: 0.010\n",
      "[104,    14] loss: 0.010\n",
      "[104,    21] loss: 0.010\n",
      "[104,    28] loss: 0.009\n",
      "[104,    35] loss: 0.008\n",
      "[104,    42] loss: 0.009\n",
      "[104,    49] loss: 0.008\n",
      "[104,    56] loss: 0.009\n",
      "[105,     7] loss: 0.010\n",
      "[105,    14] loss: 0.010\n",
      "[105,    21] loss: 0.007\n",
      "[105,    28] loss: 0.007\n",
      "[105,    35] loss: 0.010\n",
      "[105,    42] loss: 0.008\n",
      "[105,    49] loss: 0.009\n",
      "[105,    56] loss: 0.011\n",
      "[106,     7] loss: 0.009\n",
      "[106,    14] loss: 0.007\n",
      "[106,    21] loss: 0.008\n",
      "[106,    28] loss: 0.008\n",
      "[106,    35] loss: 0.009\n",
      "[106,    42] loss: 0.009\n",
      "[106,    49] loss: 0.009\n",
      "[106,    56] loss: 0.009\n",
      "[107,     7] loss: 0.007\n",
      "[107,    14] loss: 0.009\n",
      "[107,    21] loss: 0.008\n",
      "[107,    28] loss: 0.008\n",
      "[107,    35] loss: 0.010\n",
      "[107,    42] loss: 0.008\n",
      "[107,    49] loss: 0.010\n",
      "[107,    56] loss: 0.009\n",
      "[108,     7] loss: 0.010\n",
      "[108,    14] loss: 0.010\n",
      "[108,    21] loss: 0.010\n",
      "[108,    28] loss: 0.007\n",
      "[108,    35] loss: 0.010\n",
      "[108,    42] loss: 0.008\n",
      "[108,    49] loss: 0.009\n",
      "[108,    56] loss: 0.010\n",
      "[109,     7] loss: 0.009\n",
      "[109,    14] loss: 0.010\n",
      "[109,    21] loss: 0.010\n",
      "[109,    28] loss: 0.010\n",
      "[109,    35] loss: 0.007\n",
      "[109,    42] loss: 0.010\n",
      "[109,    49] loss: 0.008\n",
      "[109,    56] loss: 0.012\n",
      "[110,     7] loss: 0.007\n",
      "[110,    14] loss: 0.009\n",
      "[110,    21] loss: 0.011\n",
      "[110,    28] loss: 0.008\n",
      "[110,    35] loss: 0.008\n",
      "[110,    42] loss: 0.008\n",
      "[110,    49] loss: 0.012\n",
      "[110,    56] loss: 0.010\n",
      "[111,     7] loss: 0.010\n",
      "[111,    14] loss: 0.009\n",
      "[111,    21] loss: 0.012\n",
      "[111,    28] loss: 0.007\n",
      "[111,    35] loss: 0.009\n",
      "[111,    42] loss: 0.009\n",
      "[111,    49] loss: 0.009\n",
      "[111,    56] loss: 0.012\n",
      "[112,     7] loss: 0.010\n",
      "[112,    14] loss: 0.008\n",
      "[112,    21] loss: 0.009\n",
      "[112,    28] loss: 0.009\n",
      "[112,    35] loss: 0.008\n",
      "[112,    42] loss: 0.007\n",
      "[112,    49] loss: 0.010\n",
      "[112,    56] loss: 0.008\n",
      "[113,     7] loss: 0.010\n",
      "[113,    14] loss: 0.009\n",
      "[113,    21] loss: 0.009\n",
      "[113,    28] loss: 0.007\n",
      "[113,    35] loss: 0.009\n",
      "[113,    42] loss: 0.009\n",
      "[113,    49] loss: 0.008\n",
      "[113,    56] loss: 0.009\n",
      "[114,     7] loss: 0.008\n",
      "[114,    14] loss: 0.009\n",
      "[114,    21] loss: 0.008\n",
      "[114,    28] loss: 0.006\n",
      "[114,    35] loss: 0.010\n",
      "[114,    42] loss: 0.008\n",
      "[114,    49] loss: 0.011\n",
      "[114,    56] loss: 0.009\n",
      "[115,     7] loss: 0.007\n",
      "[115,    14] loss: 0.008\n",
      "[115,    21] loss: 0.009\n",
      "[115,    28] loss: 0.010\n",
      "[115,    35] loss: 0.010\n",
      "[115,    42] loss: 0.008\n",
      "[115,    49] loss: 0.009\n",
      "[115,    56] loss: 0.009\n",
      "[116,     7] loss: 0.009\n",
      "[116,    14] loss: 0.015\n",
      "[116,    21] loss: 0.017\n",
      "[116,    28] loss: 0.022\n",
      "[116,    35] loss: 0.019\n",
      "[116,    42] loss: 0.014\n",
      "[116,    49] loss: 0.015\n",
      "[116,    56] loss: 0.014\n",
      "[117,     7] loss: 0.015\n",
      "[117,    14] loss: 0.012\n",
      "[117,    21] loss: 0.012\n",
      "[117,    28] loss: 0.011\n",
      "[117,    35] loss: 0.011\n",
      "[117,    42] loss: 0.011\n",
      "[117,    49] loss: 0.027\n",
      "[117,    56] loss: 0.042\n",
      "[118,     7] loss: 0.076\n",
      "[118,    14] loss: 0.177\n",
      "[118,    21] loss: 0.187\n",
      "[118,    28] loss: 0.333\n",
      "[118,    35] loss: 0.388\n",
      "[118,    42] loss: 0.200\n",
      "[118,    49] loss: 0.178\n",
      "[118,    56] loss: 0.206\n",
      "[119,     7] loss: 0.160\n",
      "[119,    14] loss: 0.101\n",
      "[119,    21] loss: 0.102\n",
      "[119,    28] loss: 0.349\n",
      "[119,    35] loss: 0.871\n",
      "[119,    42] loss: 0.708\n",
      "[119,    49] loss: 0.373\n",
      "[119,    56] loss: 0.277\n",
      "[120,     7] loss: 0.097\n",
      "[120,    14] loss: 0.078\n",
      "[120,    21] loss: 0.076\n",
      "[120,    28] loss: 0.050\n",
      "[120,    35] loss: 0.057\n",
      "[120,    42] loss: 0.062\n",
      "[120,    49] loss: 0.040\n",
      "[120,    56] loss: 0.041\n",
      "[121,     7] loss: 0.039\n",
      "[121,    14] loss: 0.032\n",
      "[121,    21] loss: 0.048\n",
      "[121,    28] loss: 0.030\n",
      "[121,    35] loss: 0.039\n",
      "[121,    42] loss: 0.031\n",
      "[121,    49] loss: 0.040\n",
      "[121,    56] loss: 0.031\n",
      "[122,     7] loss: 0.037\n",
      "[122,    14] loss: 0.044\n",
      "[122,    21] loss: 0.031\n",
      "[122,    28] loss: 0.032\n",
      "[122,    35] loss: 0.030\n",
      "[122,    42] loss: 0.031\n",
      "[122,    49] loss: 0.028\n",
      "[122,    56] loss: 0.030\n",
      "[123,     7] loss: 0.029\n",
      "[123,    14] loss: 0.032\n",
      "[123,    21] loss: 0.031\n",
      "[123,    28] loss: 0.035\n",
      "[123,    35] loss: 0.022\n",
      "[123,    42] loss: 0.029\n",
      "[123,    49] loss: 0.030\n",
      "[123,    56] loss: 0.026\n",
      "[124,     7] loss: 0.020\n",
      "[124,    14] loss: 0.030\n",
      "[124,    21] loss: 0.025\n",
      "[124,    28] loss: 0.024\n",
      "[124,    35] loss: 0.039\n",
      "[124,    42] loss: 0.025\n",
      "[124,    49] loss: 0.023\n",
      "[124,    56] loss: 0.021\n",
      "[125,     7] loss: 0.021\n",
      "[125,    14] loss: 0.021\n",
      "[125,    21] loss: 0.025\n",
      "[125,    28] loss: 0.028\n",
      "[125,    35] loss: 0.021\n",
      "[125,    42] loss: 0.028\n",
      "[125,    49] loss: 0.021\n",
      "[125,    56] loss: 0.032\n",
      "[126,     7] loss: 0.025\n",
      "[126,    14] loss: 0.025\n",
      "[126,    21] loss: 0.024\n",
      "[126,    28] loss: 0.021\n",
      "[126,    35] loss: 0.022\n",
      "[126,    42] loss: 0.023\n",
      "[126,    49] loss: 0.020\n",
      "[126,    56] loss: 0.023\n",
      "[127,     7] loss: 0.027\n",
      "[127,    14] loss: 0.021\n",
      "[127,    21] loss: 0.024\n",
      "[127,    28] loss: 0.016\n",
      "[127,    35] loss: 0.022\n",
      "[127,    42] loss: 0.019\n",
      "[127,    49] loss: 0.023\n",
      "[127,    56] loss: 0.022\n",
      "[128,     7] loss: 0.019\n",
      "[128,    14] loss: 0.020\n",
      "[128,    21] loss: 0.024\n",
      "[128,    28] loss: 0.021\n",
      "[128,    35] loss: 0.021\n",
      "[128,    42] loss: 0.021\n",
      "[128,    49] loss: 0.018\n",
      "[128,    56] loss: 0.021\n",
      "[129,     7] loss: 0.015\n",
      "[129,    14] loss: 0.016\n",
      "[129,    21] loss: 0.020\n",
      "[129,    28] loss: 0.024\n",
      "[129,    35] loss: 0.022\n",
      "[129,    42] loss: 0.018\n",
      "[129,    49] loss: 0.015\n",
      "[129,    56] loss: 0.024\n",
      "[130,     7] loss: 0.019\n",
      "[130,    14] loss: 0.019\n",
      "[130,    21] loss: 0.018\n",
      "[130,    28] loss: 0.018\n",
      "[130,    35] loss: 0.021\n",
      "[130,    42] loss: 0.020\n",
      "[130,    49] loss: 0.018\n",
      "[130,    56] loss: 0.015\n",
      "[131,     7] loss: 0.016\n",
      "[131,    14] loss: 0.021\n",
      "[131,    21] loss: 0.016\n",
      "[131,    28] loss: 0.019\n",
      "[131,    35] loss: 0.016\n",
      "[131,    42] loss: 0.018\n",
      "[131,    49] loss: 0.013\n",
      "[131,    56] loss: 0.016\n",
      "[132,     7] loss: 0.017\n",
      "[132,    14] loss: 0.014\n",
      "[132,    21] loss: 0.017\n",
      "[132,    28] loss: 0.020\n",
      "[132,    35] loss: 0.015\n",
      "[132,    42] loss: 0.015\n",
      "[132,    49] loss: 0.017\n",
      "[132,    56] loss: 0.020\n",
      "[133,     7] loss: 0.019\n",
      "[133,    14] loss: 0.019\n",
      "[133,    21] loss: 0.016\n",
      "[133,    28] loss: 0.016\n",
      "[133,    35] loss: 0.017\n",
      "[133,    42] loss: 0.018\n",
      "[133,    49] loss: 0.016\n",
      "[133,    56] loss: 0.014\n",
      "[134,     7] loss: 0.016\n",
      "[134,    14] loss: 0.014\n",
      "[134,    21] loss: 0.017\n",
      "[134,    28] loss: 0.019\n",
      "[134,    35] loss: 0.014\n",
      "[134,    42] loss: 0.013\n",
      "[134,    49] loss: 0.018\n",
      "[134,    56] loss: 0.017\n",
      "[135,     7] loss: 0.020\n",
      "[135,    14] loss: 0.015\n",
      "[135,    21] loss: 0.012\n",
      "[135,    28] loss: 0.014\n",
      "[135,    35] loss: 0.016\n",
      "[135,    42] loss: 0.018\n",
      "[135,    49] loss: 0.015\n",
      "[135,    56] loss: 0.018\n",
      "[136,     7] loss: 0.017\n",
      "[136,    14] loss: 0.014\n",
      "[136,    21] loss: 0.015\n",
      "[136,    28] loss: 0.017\n",
      "[136,    35] loss: 0.016\n",
      "[136,    42] loss: 0.017\n",
      "[136,    49] loss: 0.017\n",
      "[136,    56] loss: 0.013\n",
      "[137,     7] loss: 0.012\n",
      "[137,    14] loss: 0.015\n",
      "[137,    21] loss: 0.013\n",
      "[137,    28] loss: 0.015\n",
      "[137,    35] loss: 0.015\n",
      "[137,    42] loss: 0.015\n",
      "[137,    49] loss: 0.016\n",
      "[137,    56] loss: 0.013\n",
      "[138,     7] loss: 0.016\n",
      "[138,    14] loss: 0.016\n",
      "[138,    21] loss: 0.014\n",
      "[138,    28] loss: 0.014\n",
      "[138,    35] loss: 0.018\n",
      "[138,    42] loss: 0.015\n",
      "[138,    49] loss: 0.014\n",
      "[138,    56] loss: 0.017\n",
      "[139,     7] loss: 0.014\n",
      "[139,    14] loss: 0.013\n",
      "[139,    21] loss: 0.014\n",
      "[139,    28] loss: 0.019\n",
      "[139,    35] loss: 0.014\n",
      "[139,    42] loss: 0.011\n",
      "[139,    49] loss: 0.014\n",
      "[139,    56] loss: 0.016\n",
      "[140,     7] loss: 0.013\n",
      "[140,    14] loss: 0.012\n",
      "[140,    21] loss: 0.013\n",
      "[140,    28] loss: 0.017\n",
      "[140,    35] loss: 0.016\n",
      "[140,    42] loss: 0.017\n",
      "[140,    49] loss: 0.016\n",
      "[140,    56] loss: 0.016\n",
      "[141,     7] loss: 0.015\n",
      "[141,    14] loss: 0.013\n",
      "[141,    21] loss: 0.015\n",
      "[141,    28] loss: 0.012\n",
      "[141,    35] loss: 0.011\n",
      "[141,    42] loss: 0.015\n",
      "[141,    49] loss: 0.015\n",
      "[141,    56] loss: 0.014\n",
      "[142,     7] loss: 0.014\n",
      "[142,    14] loss: 0.012\n",
      "[142,    21] loss: 0.016\n",
      "[142,    28] loss: 0.013\n",
      "[142,    35] loss: 0.014\n",
      "[142,    42] loss: 0.015\n",
      "[142,    49] loss: 0.017\n",
      "[142,    56] loss: 0.013\n",
      "[143,     7] loss: 0.014\n",
      "[143,    14] loss: 0.012\n",
      "[143,    21] loss: 0.013\n",
      "[143,    28] loss: 0.011\n",
      "[143,    35] loss: 0.012\n",
      "[143,    42] loss: 0.015\n",
      "[143,    49] loss: 0.012\n",
      "[143,    56] loss: 0.015\n",
      "[144,     7] loss: 0.014\n",
      "[144,    14] loss: 0.014\n",
      "[144,    21] loss: 0.013\n",
      "[144,    28] loss: 0.011\n",
      "[144,    35] loss: 0.013\n",
      "[144,    42] loss: 0.012\n",
      "[144,    49] loss: 0.014\n",
      "[144,    56] loss: 0.016\n",
      "[145,     7] loss: 0.013\n",
      "[145,    14] loss: 0.012\n",
      "[145,    21] loss: 0.016\n",
      "[145,    28] loss: 0.013\n",
      "[145,    35] loss: 0.009\n",
      "[145,    42] loss: 0.012\n",
      "[145,    49] loss: 0.013\n",
      "[145,    56] loss: 0.013\n",
      "[146,     7] loss: 0.013\n",
      "[146,    14] loss: 0.009\n",
      "[146,    21] loss: 0.013\n",
      "[146,    28] loss: 0.014\n",
      "[146,    35] loss: 0.013\n",
      "[146,    42] loss: 0.012\n",
      "[146,    49] loss: 0.022\n",
      "[146,    56] loss: 0.013\n",
      "[147,     7] loss: 0.013\n",
      "[147,    14] loss: 0.017\n",
      "[147,    21] loss: 0.013\n",
      "[147,    28] loss: 0.013\n",
      "[147,    35] loss: 0.013\n",
      "[147,    42] loss: 0.017\n",
      "[147,    49] loss: 0.013\n",
      "[147,    56] loss: 0.014\n",
      "[148,     7] loss: 0.011\n",
      "[148,    14] loss: 0.011\n",
      "[148,    21] loss: 0.015\n",
      "[148,    28] loss: 0.013\n",
      "[148,    35] loss: 0.013\n",
      "[148,    42] loss: 0.013\n",
      "[148,    49] loss: 0.010\n",
      "[148,    56] loss: 0.013\n",
      "[149,     7] loss: 0.015\n",
      "[149,    14] loss: 0.014\n",
      "[149,    21] loss: 0.014\n",
      "[149,    28] loss: 0.013\n",
      "[149,    35] loss: 0.011\n",
      "[149,    42] loss: 0.013\n",
      "[149,    49] loss: 0.014\n",
      "[149,    56] loss: 0.014\n",
      "[150,     7] loss: 0.013\n",
      "[150,    14] loss: 0.012\n",
      "[150,    21] loss: 0.012\n",
      "[150,    28] loss: 0.013\n",
      "[150,    35] loss: 0.014\n",
      "[150,    42] loss: 0.014\n",
      "[150,    49] loss: 0.012\n",
      "[150,    56] loss: 0.009\n",
      "[151,     7] loss: 0.012\n",
      "[151,    14] loss: 0.011\n",
      "[151,    21] loss: 0.012\n",
      "[151,    28] loss: 0.011\n",
      "[151,    35] loss: 0.011\n",
      "[151,    42] loss: 0.011\n",
      "[151,    49] loss: 0.009\n",
      "[151,    56] loss: 0.011\n",
      "[152,     7] loss: 0.011\n",
      "[152,    14] loss: 0.011\n",
      "[152,    21] loss: 0.011\n",
      "[152,    28] loss: 0.011\n",
      "[152,    35] loss: 0.013\n",
      "[152,    42] loss: 0.012\n",
      "[152,    49] loss: 0.014\n",
      "[152,    56] loss: 0.015\n",
      "[153,     7] loss: 0.012\n",
      "[153,    14] loss: 0.010\n",
      "[153,    21] loss: 0.013\n",
      "[153,    28] loss: 0.012\n",
      "[153,    35] loss: 0.013\n",
      "[153,    42] loss: 0.012\n",
      "[153,    49] loss: 0.012\n",
      "[153,    56] loss: 0.011\n",
      "[154,     7] loss: 0.011\n",
      "[154,    14] loss: 0.008\n",
      "[154,    21] loss: 0.012\n",
      "[154,    28] loss: 0.011\n",
      "[154,    35] loss: 0.012\n",
      "[154,    42] loss: 0.009\n",
      "[154,    49] loss: 0.013\n",
      "[154,    56] loss: 0.012\n",
      "[155,     7] loss: 0.010\n",
      "[155,    14] loss: 0.010\n",
      "[155,    21] loss: 0.014\n",
      "[155,    28] loss: 0.010\n",
      "[155,    35] loss: 0.013\n",
      "[155,    42] loss: 0.012\n",
      "[155,    49] loss: 0.013\n",
      "[155,    56] loss: 0.011\n",
      "[156,     7] loss: 0.009\n",
      "[156,    14] loss: 0.013\n",
      "[156,    21] loss: 0.014\n",
      "[156,    28] loss: 0.008\n",
      "[156,    35] loss: 0.011\n",
      "[156,    42] loss: 0.009\n",
      "[156,    49] loss: 0.010\n",
      "[156,    56] loss: 0.011\n",
      "[157,     7] loss: 0.011\n",
      "[157,    14] loss: 0.010\n",
      "[157,    21] loss: 0.011\n",
      "[157,    28] loss: 0.013\n",
      "[157,    35] loss: 0.011\n",
      "[157,    42] loss: 0.013\n",
      "[157,    49] loss: 0.013\n",
      "[157,    56] loss: 0.013\n",
      "[158,     7] loss: 0.011\n",
      "[158,    14] loss: 0.012\n",
      "[158,    21] loss: 0.011\n",
      "[158,    28] loss: 0.011\n",
      "[158,    35] loss: 0.010\n",
      "[158,    42] loss: 0.010\n",
      "[158,    49] loss: 0.014\n",
      "[158,    56] loss: 0.011\n",
      "[159,     7] loss: 0.011\n",
      "[159,    14] loss: 0.009\n",
      "[159,    21] loss: 0.010\n",
      "[159,    28] loss: 0.010\n",
      "[159,    35] loss: 0.012\n",
      "[159,    42] loss: 0.010\n",
      "[159,    49] loss: 0.013\n",
      "[159,    56] loss: 0.011\n",
      "[160,     7] loss: 0.011\n",
      "[160,    14] loss: 0.009\n",
      "[160,    21] loss: 0.010\n",
      "[160,    28] loss: 0.014\n",
      "[160,    35] loss: 0.010\n",
      "[160,    42] loss: 0.010\n",
      "[160,    49] loss: 0.012\n",
      "[160,    56] loss: 0.009\n",
      "[161,     7] loss: 0.011\n",
      "[161,    14] loss: 0.010\n",
      "[161,    21] loss: 0.009\n",
      "[161,    28] loss: 0.010\n",
      "[161,    35] loss: 0.008\n",
      "[161,    42] loss: 0.010\n",
      "[161,    49] loss: 0.011\n",
      "[161,    56] loss: 0.009\n",
      "[162,     7] loss: 0.010\n",
      "[162,    14] loss: 0.008\n",
      "[162,    21] loss: 0.010\n",
      "[162,    28] loss: 0.013\n",
      "[162,    35] loss: 0.010\n",
      "[162,    42] loss: 0.013\n",
      "[162,    49] loss: 0.011\n",
      "[162,    56] loss: 0.010\n",
      "[163,     7] loss: 0.010\n",
      "[163,    14] loss: 0.009\n",
      "[163,    21] loss: 0.011\n",
      "[163,    28] loss: 0.010\n",
      "[163,    35] loss: 0.010\n",
      "[163,    42] loss: 0.012\n",
      "[163,    49] loss: 0.009\n",
      "[163,    56] loss: 0.010\n",
      "[164,     7] loss: 0.012\n",
      "[164,    14] loss: 0.010\n",
      "[164,    21] loss: 0.011\n",
      "[164,    28] loss: 0.011\n",
      "[164,    35] loss: 0.012\n",
      "[164,    42] loss: 0.012\n",
      "[164,    49] loss: 0.009\n",
      "[164,    56] loss: 0.010\n",
      "[165,     7] loss: 0.014\n",
      "[165,    14] loss: 0.008\n",
      "[165,    21] loss: 0.011\n",
      "[165,    28] loss: 0.010\n",
      "[165,    35] loss: 0.013\n",
      "[165,    42] loss: 0.012\n",
      "[165,    49] loss: 0.008\n",
      "[165,    56] loss: 0.011\n",
      "[166,     7] loss: 0.011\n",
      "[166,    14] loss: 0.013\n",
      "[166,    21] loss: 0.009\n",
      "[166,    28] loss: 0.010\n",
      "[166,    35] loss: 0.009\n",
      "[166,    42] loss: 0.011\n",
      "[166,    49] loss: 0.009\n",
      "[166,    56] loss: 0.011\n",
      "[167,     7] loss: 0.009\n",
      "[167,    14] loss: 0.011\n",
      "[167,    21] loss: 0.010\n",
      "[167,    28] loss: 0.011\n",
      "[167,    35] loss: 0.011\n",
      "[167,    42] loss: 0.011\n",
      "[167,    49] loss: 0.008\n",
      "[167,    56] loss: 0.009\n",
      "[168,     7] loss: 0.009\n",
      "[168,    14] loss: 0.011\n",
      "[168,    21] loss: 0.009\n",
      "[168,    28] loss: 0.009\n",
      "[168,    35] loss: 0.011\n",
      "[168,    42] loss: 0.010\n",
      "[168,    49] loss: 0.009\n",
      "[168,    56] loss: 0.011\n",
      "[169,     7] loss: 0.010\n",
      "[169,    14] loss: 0.010\n",
      "[169,    21] loss: 0.009\n",
      "[169,    28] loss: 0.010\n",
      "[169,    35] loss: 0.011\n",
      "[169,    42] loss: 0.009\n",
      "[169,    49] loss: 0.011\n",
      "[169,    56] loss: 0.010\n",
      "[170,     7] loss: 0.011\n",
      "[170,    14] loss: 0.009\n",
      "[170,    21] loss: 0.008\n",
      "[170,    28] loss: 0.011\n",
      "[170,    35] loss: 0.009\n",
      "[170,    42] loss: 0.009\n",
      "[170,    49] loss: 0.011\n",
      "[170,    56] loss: 0.012\n",
      "[171,     7] loss: 0.010\n",
      "[171,    14] loss: 0.011\n",
      "[171,    21] loss: 0.008\n",
      "[171,    28] loss: 0.011\n",
      "[171,    35] loss: 0.009\n",
      "[171,    42] loss: 0.011\n",
      "[171,    49] loss: 0.011\n",
      "[171,    56] loss: 0.008\n",
      "[172,     7] loss: 0.010\n",
      "[172,    14] loss: 0.010\n",
      "[172,    21] loss: 0.009\n",
      "[172,    28] loss: 0.009\n",
      "[172,    35] loss: 0.011\n",
      "[172,    42] loss: 0.008\n",
      "[172,    49] loss: 0.010\n",
      "[172,    56] loss: 0.011\n",
      "[173,     7] loss: 0.012\n",
      "[173,    14] loss: 0.009\n",
      "[173,    21] loss: 0.010\n",
      "[173,    28] loss: 0.009\n",
      "[173,    35] loss: 0.010\n",
      "[173,    42] loss: 0.008\n",
      "[173,    49] loss: 0.010\n",
      "[173,    56] loss: 0.010\n",
      "[174,     7] loss: 0.011\n",
      "[174,    14] loss: 0.009\n",
      "[174,    21] loss: 0.008\n",
      "[174,    28] loss: 0.010\n",
      "[174,    35] loss: 0.011\n",
      "[174,    42] loss: 0.009\n",
      "[174,    49] loss: 0.012\n",
      "[174,    56] loss: 0.011\n",
      "[175,     7] loss: 0.010\n",
      "[175,    14] loss: 0.010\n",
      "[175,    21] loss: 0.008\n",
      "[175,    28] loss: 0.009\n",
      "[175,    35] loss: 0.007\n",
      "[175,    42] loss: 0.007\n",
      "[175,    49] loss: 0.011\n",
      "[175,    56] loss: 0.008\n",
      "[176,     7] loss: 0.008\n",
      "[176,    14] loss: 0.009\n",
      "[176,    21] loss: 0.009\n",
      "[176,    28] loss: 0.008\n",
      "[176,    35] loss: 0.010\n",
      "[176,    42] loss: 0.011\n",
      "[176,    49] loss: 0.011\n",
      "[176,    56] loss: 0.010\n",
      "[177,     7] loss: 0.009\n",
      "[177,    14] loss: 0.010\n",
      "[177,    21] loss: 0.008\n",
      "[177,    28] loss: 0.009\n",
      "[177,    35] loss: 0.012\n",
      "[177,    42] loss: 0.011\n",
      "[177,    49] loss: 0.010\n",
      "[177,    56] loss: 0.009\n",
      "[178,     7] loss: 0.010\n",
      "[178,    14] loss: 0.010\n",
      "[178,    21] loss: 0.008\n",
      "[178,    28] loss: 0.008\n",
      "[178,    35] loss: 0.010\n",
      "[178,    42] loss: 0.007\n",
      "[178,    49] loss: 0.010\n",
      "[178,    56] loss: 0.009\n",
      "[179,     7] loss: 0.010\n",
      "[179,    14] loss: 0.010\n",
      "[179,    21] loss: 0.010\n",
      "[179,    28] loss: 0.011\n",
      "[179,    35] loss: 0.010\n",
      "[179,    42] loss: 0.007\n",
      "[179,    49] loss: 0.009\n",
      "[179,    56] loss: 0.009\n",
      "[180,     7] loss: 0.010\n",
      "[180,    14] loss: 0.008\n",
      "[180,    21] loss: 0.010\n",
      "[180,    28] loss: 0.009\n",
      "[180,    35] loss: 0.009\n",
      "[180,    42] loss: 0.009\n",
      "[180,    49] loss: 0.010\n",
      "[180,    56] loss: 0.010\n",
      "[181,     7] loss: 0.006\n",
      "[181,    14] loss: 0.010\n",
      "[181,    21] loss: 0.010\n",
      "[181,    28] loss: 0.008\n",
      "[181,    35] loss: 0.008\n",
      "[181,    42] loss: 0.008\n",
      "[181,    49] loss: 0.010\n",
      "[181,    56] loss: 0.009\n",
      "[182,     7] loss: 0.008\n",
      "[182,    14] loss: 0.010\n",
      "[182,    21] loss: 0.010\n",
      "[182,    28] loss: 0.009\n",
      "[182,    35] loss: 0.009\n",
      "[182,    42] loss: 0.010\n",
      "[182,    49] loss: 0.008\n",
      "[182,    56] loss: 0.009\n",
      "[183,     7] loss: 0.006\n",
      "[183,    14] loss: 0.007\n",
      "[183,    21] loss: 0.010\n",
      "[183,    28] loss: 0.010\n",
      "[183,    35] loss: 0.011\n",
      "[183,    42] loss: 0.011\n",
      "[183,    49] loss: 0.011\n",
      "[183,    56] loss: 0.009\n",
      "[184,     7] loss: 0.009\n",
      "[184,    14] loss: 0.009\n",
      "[184,    21] loss: 0.010\n",
      "[184,    28] loss: 0.009\n",
      "[184,    35] loss: 0.007\n",
      "[184,    42] loss: 0.007\n",
      "[184,    49] loss: 0.007\n",
      "[184,    56] loss: 0.011\n",
      "[185,     7] loss: 0.008\n",
      "[185,    14] loss: 0.011\n",
      "[185,    21] loss: 0.010\n",
      "[185,    28] loss: 0.008\n",
      "[185,    35] loss: 0.009\n",
      "[185,    42] loss: 0.011\n",
      "[185,    49] loss: 0.008\n",
      "[185,    56] loss: 0.007\n",
      "[186,     7] loss: 0.009\n",
      "[186,    14] loss: 0.010\n",
      "[186,    21] loss: 0.007\n",
      "[186,    28] loss: 0.009\n",
      "[186,    35] loss: 0.008\n",
      "[186,    42] loss: 0.009\n",
      "[186,    49] loss: 0.008\n",
      "[186,    56] loss: 0.012\n",
      "[187,     7] loss: 0.009\n",
      "[187,    14] loss: 0.009\n",
      "[187,    21] loss: 0.009\n",
      "[187,    28] loss: 0.009\n",
      "[187,    35] loss: 0.008\n",
      "[187,    42] loss: 0.009\n",
      "[187,    49] loss: 0.011\n",
      "[187,    56] loss: 0.009\n",
      "[188,     7] loss: 0.008\n",
      "[188,    14] loss: 0.010\n",
      "[188,    21] loss: 0.008\n",
      "[188,    28] loss: 0.008\n",
      "[188,    35] loss: 0.012\n",
      "[188,    42] loss: 0.009\n",
      "[188,    49] loss: 0.009\n",
      "[188,    56] loss: 0.009\n",
      "[189,     7] loss: 0.011\n",
      "[189,    14] loss: 0.010\n",
      "[189,    21] loss: 0.009\n",
      "[189,    28] loss: 0.010\n",
      "[189,    35] loss: 0.009\n",
      "[189,    42] loss: 0.009\n",
      "[189,    49] loss: 0.009\n",
      "[189,    56] loss: 0.008\n",
      "[190,     7] loss: 0.007\n",
      "[190,    14] loss: 0.011\n",
      "[190,    21] loss: 0.009\n",
      "[190,    28] loss: 0.008\n",
      "[190,    35] loss: 0.008\n",
      "[190,    42] loss: 0.009\n",
      "[190,    49] loss: 0.008\n",
      "[190,    56] loss: 0.007\n",
      "[191,     7] loss: 0.008\n",
      "[191,    14] loss: 0.009\n",
      "[191,    21] loss: 0.008\n",
      "[191,    28] loss: 0.007\n",
      "[191,    35] loss: 0.006\n",
      "[191,    42] loss: 0.008\n",
      "[191,    49] loss: 0.010\n",
      "[191,    56] loss: 0.008\n",
      "[192,     7] loss: 0.010\n",
      "[192,    14] loss: 0.009\n",
      "[192,    21] loss: 0.008\n",
      "[192,    28] loss: 0.007\n",
      "[192,    35] loss: 0.007\n",
      "[192,    42] loss: 0.011\n",
      "[192,    49] loss: 0.010\n",
      "[192,    56] loss: 0.010\n",
      "[193,     7] loss: 0.009\n",
      "[193,    14] loss: 0.010\n",
      "[193,    21] loss: 0.008\n",
      "[193,    28] loss: 0.009\n",
      "[193,    35] loss: 0.010\n",
      "[193,    42] loss: 0.010\n",
      "[193,    49] loss: 0.009\n",
      "[193,    56] loss: 0.007\n",
      "[194,     7] loss: 0.008\n",
      "[194,    14] loss: 0.010\n",
      "[194,    21] loss: 0.009\n",
      "[194,    28] loss: 0.008\n",
      "[194,    35] loss: 0.009\n",
      "[194,    42] loss: 0.009\n",
      "[194,    49] loss: 0.008\n",
      "[194,    56] loss: 0.006\n",
      "[195,     7] loss: 0.007\n",
      "[195,    14] loss: 0.010\n",
      "[195,    21] loss: 0.007\n",
      "[195,    28] loss: 0.008\n",
      "[195,    35] loss: 0.012\n",
      "[195,    42] loss: 0.009\n",
      "[195,    49] loss: 0.007\n",
      "[195,    56] loss: 0.008\n",
      "[196,     7] loss: 0.006\n",
      "[196,    14] loss: 0.009\n",
      "[196,    21] loss: 0.007\n",
      "[196,    28] loss: 0.009\n",
      "[196,    35] loss: 0.009\n",
      "[196,    42] loss: 0.008\n",
      "[196,    49] loss: 0.008\n",
      "[196,    56] loss: 0.010\n",
      "[197,     7] loss: 0.010\n",
      "[197,    14] loss: 0.008\n",
      "[197,    21] loss: 0.007\n",
      "[197,    28] loss: 0.008\n",
      "[197,    35] loss: 0.008\n",
      "[197,    42] loss: 0.009\n",
      "[197,    49] loss: 0.008\n",
      "[197,    56] loss: 0.008\n",
      "[198,     7] loss: 0.007\n",
      "[198,    14] loss: 0.009\n",
      "[198,    21] loss: 0.008\n",
      "[198,    28] loss: 0.007\n",
      "[198,    35] loss: 0.007\n",
      "[198,    42] loss: 0.007\n",
      "[198,    49] loss: 0.009\n",
      "[198,    56] loss: 0.009\n",
      "[199,     7] loss: 0.010\n",
      "[199,    14] loss: 0.010\n",
      "[199,    21] loss: 0.007\n",
      "[199,    28] loss: 0.009\n",
      "[199,    35] loss: 0.008\n",
      "[199,    42] loss: 0.007\n",
      "[199,    49] loss: 0.010\n",
      "[199,    56] loss: 0.010\n",
      "[200,     7] loss: 0.007\n",
      "[200,    14] loss: 0.009\n",
      "[200,    21] loss: 0.007\n",
      "[200,    28] loss: 0.009\n",
      "[200,    35] loss: 0.009\n",
      "[200,    42] loss: 0.008\n",
      "[200,    49] loss: 0.009\n",
      "[200,    56] loss: 0.009\n",
      "[201,     7] loss: 0.007\n",
      "[201,    14] loss: 0.007\n",
      "[201,    21] loss: 0.008\n",
      "[201,    28] loss: 0.008\n",
      "[201,    35] loss: 0.009\n",
      "[201,    42] loss: 0.008\n",
      "[201,    49] loss: 0.008\n",
      "[201,    56] loss: 0.009\n",
      "[202,     7] loss: 0.008\n",
      "[202,    14] loss: 0.006\n",
      "[202,    21] loss: 0.009\n",
      "[202,    28] loss: 0.007\n",
      "[202,    35] loss: 0.007\n",
      "[202,    42] loss: 0.007\n",
      "[202,    49] loss: 0.007\n",
      "[202,    56] loss: 0.008\n",
      "[203,     7] loss: 0.007\n",
      "[203,    14] loss: 0.008\n",
      "[203,    21] loss: 0.010\n",
      "[203,    28] loss: 0.008\n",
      "[203,    35] loss: 0.009\n",
      "[203,    42] loss: 0.007\n",
      "[203,    49] loss: 0.007\n",
      "[203,    56] loss: 0.006\n",
      "[204,     7] loss: 0.009\n",
      "[204,    14] loss: 0.008\n",
      "[204,    21] loss: 0.008\n",
      "[204,    28] loss: 0.006\n",
      "[204,    35] loss: 0.009\n",
      "[204,    42] loss: 0.008\n",
      "[204,    49] loss: 0.008\n",
      "[204,    56] loss: 0.010\n",
      "[205,     7] loss: 0.008\n",
      "[205,    14] loss: 0.007\n",
      "[205,    21] loss: 0.007\n",
      "[205,    28] loss: 0.008\n",
      "[205,    35] loss: 0.008\n",
      "[205,    42] loss: 0.009\n",
      "[205,    49] loss: 0.007\n",
      "[205,    56] loss: 0.008\n",
      "[206,     7] loss: 0.009\n",
      "[206,    14] loss: 0.009\n",
      "[206,    21] loss: 0.008\n",
      "[206,    28] loss: 0.008\n",
      "[206,    35] loss: 0.007\n",
      "[206,    42] loss: 0.010\n",
      "[206,    49] loss: 0.009\n",
      "[206,    56] loss: 0.008\n",
      "[207,     7] loss: 0.008\n",
      "[207,    14] loss: 0.008\n",
      "[207,    21] loss: 0.007\n",
      "[207,    28] loss: 0.006\n",
      "[207,    35] loss: 0.010\n",
      "[207,    42] loss: 0.007\n",
      "[207,    49] loss: 0.010\n",
      "[207,    56] loss: 0.009\n",
      "[208,     7] loss: 0.008\n",
      "[208,    14] loss: 0.007\n",
      "[208,    21] loss: 0.009\n",
      "[208,    28] loss: 0.008\n",
      "[208,    35] loss: 0.007\n",
      "[208,    42] loss: 0.008\n",
      "[208,    49] loss: 0.010\n",
      "[208,    56] loss: 0.007\n",
      "[209,     7] loss: 0.008\n",
      "[209,    14] loss: 0.007\n",
      "[209,    21] loss: 0.010\n",
      "[209,    28] loss: 0.008\n",
      "[209,    35] loss: 0.007\n",
      "[209,    42] loss: 0.009\n",
      "[209,    49] loss: 0.010\n",
      "[209,    56] loss: 0.010\n",
      "[210,     7] loss: 0.006\n",
      "[210,    14] loss: 0.007\n",
      "[210,    21] loss: 0.008\n",
      "[210,    28] loss: 0.008\n",
      "[210,    35] loss: 0.007\n",
      "[210,    42] loss: 0.008\n",
      "[210,    49] loss: 0.008\n",
      "[210,    56] loss: 0.007\n",
      "[211,     7] loss: 0.007\n",
      "[211,    14] loss: 0.008\n",
      "[211,    21] loss: 0.008\n",
      "[211,    28] loss: 0.008\n",
      "[211,    35] loss: 0.009\n",
      "[211,    42] loss: 0.006\n",
      "[211,    49] loss: 0.007\n",
      "[211,    56] loss: 0.008\n",
      "[212,     7] loss: 0.007\n",
      "[212,    14] loss: 0.008\n",
      "[212,    21] loss: 0.008\n",
      "[212,    28] loss: 0.009\n",
      "[212,    35] loss: 0.007\n",
      "[212,    42] loss: 0.009\n",
      "[212,    49] loss: 0.007\n",
      "[212,    56] loss: 0.007\n",
      "[213,     7] loss: 0.008\n",
      "[213,    14] loss: 0.009\n",
      "[213,    21] loss: 0.009\n",
      "[213,    28] loss: 0.008\n",
      "[213,    35] loss: 0.007\n",
      "[213,    42] loss: 0.008\n",
      "[213,    49] loss: 0.006\n",
      "[213,    56] loss: 0.008\n",
      "[214,     7] loss: 0.007\n",
      "[214,    14] loss: 0.006\n",
      "[214,    21] loss: 0.006\n",
      "[214,    28] loss: 0.007\n",
      "[214,    35] loss: 0.006\n",
      "[214,    42] loss: 0.008\n",
      "[214,    49] loss: 0.008\n",
      "[214,    56] loss: 0.009\n",
      "[215,     7] loss: 0.008\n",
      "[215,    14] loss: 0.008\n",
      "[215,    21] loss: 0.006\n",
      "[215,    28] loss: 0.007\n",
      "[215,    35] loss: 0.007\n",
      "[215,    42] loss: 0.008\n",
      "[215,    49] loss: 0.006\n",
      "[215,    56] loss: 0.009\n",
      "[216,     7] loss: 0.008\n",
      "[216,    14] loss: 0.007\n",
      "[216,    21] loss: 0.006\n",
      "[216,    28] loss: 0.007\n",
      "[216,    35] loss: 0.007\n",
      "[216,    42] loss: 0.008\n",
      "[216,    49] loss: 0.008\n",
      "[216,    56] loss: 0.008\n",
      "[217,     7] loss: 0.006\n",
      "[217,    14] loss: 0.007\n",
      "[217,    21] loss: 0.007\n",
      "[217,    28] loss: 0.007\n",
      "[217,    35] loss: 0.009\n",
      "[217,    42] loss: 0.008\n",
      "[217,    49] loss: 0.007\n",
      "[217,    56] loss: 0.007\n",
      "[218,     7] loss: 0.006\n",
      "[218,    14] loss: 0.008\n",
      "[218,    21] loss: 0.007\n",
      "[218,    28] loss: 0.007\n",
      "[218,    35] loss: 0.006\n",
      "[218,    42] loss: 0.009\n",
      "[218,    49] loss: 0.007\n",
      "[218,    56] loss: 0.007\n",
      "[219,     7] loss: 0.007\n",
      "[219,    14] loss: 0.007\n",
      "[219,    21] loss: 0.008\n",
      "[219,    28] loss: 0.007\n",
      "[219,    35] loss: 0.007\n",
      "[219,    42] loss: 0.007\n",
      "[219,    49] loss: 0.007\n",
      "[219,    56] loss: 0.008\n",
      "[220,     7] loss: 0.006\n",
      "[220,    14] loss: 0.007\n",
      "[220,    21] loss: 0.008\n",
      "[220,    28] loss: 0.006\n",
      "[220,    35] loss: 0.006\n",
      "[220,    42] loss: 0.008\n",
      "[220,    49] loss: 0.008\n",
      "[220,    56] loss: 0.008\n",
      "[221,     7] loss: 0.006\n",
      "[221,    14] loss: 0.008\n",
      "[221,    21] loss: 0.008\n",
      "[221,    28] loss: 0.006\n",
      "[221,    35] loss: 0.007\n",
      "[221,    42] loss: 0.007\n",
      "[221,    49] loss: 0.007\n",
      "[221,    56] loss: 0.009\n",
      "[222,     7] loss: 0.007\n",
      "[222,    14] loss: 0.007\n",
      "[222,    21] loss: 0.008\n",
      "[222,    28] loss: 0.006\n",
      "[222,    35] loss: 0.009\n",
      "[222,    42] loss: 0.006\n",
      "[222,    49] loss: 0.009\n",
      "[222,    56] loss: 0.008\n",
      "[223,     7] loss: 0.008\n",
      "[223,    14] loss: 0.009\n",
      "[223,    21] loss: 0.007\n",
      "[223,    28] loss: 0.006\n",
      "[223,    35] loss: 0.006\n",
      "[223,    42] loss: 0.006\n",
      "[223,    49] loss: 0.007\n",
      "[223,    56] loss: 0.008\n",
      "[224,     7] loss: 0.007\n",
      "[224,    14] loss: 0.006\n",
      "[224,    21] loss: 0.008\n",
      "[224,    28] loss: 0.008\n",
      "[224,    35] loss: 0.007\n",
      "[224,    42] loss: 0.008\n",
      "[224,    49] loss: 0.007\n",
      "[224,    56] loss: 0.006\n",
      "[225,     7] loss: 0.007\n",
      "[225,    14] loss: 0.008\n",
      "[225,    21] loss: 0.009\n",
      "[225,    28] loss: 0.007\n",
      "[225,    35] loss: 0.006\n",
      "[225,    42] loss: 0.007\n",
      "[225,    49] loss: 0.006\n",
      "[225,    56] loss: 0.008\n",
      "[226,     7] loss: 0.007\n",
      "[226,    14] loss: 0.006\n",
      "[226,    21] loss: 0.009\n",
      "[226,    28] loss: 0.008\n",
      "[226,    35] loss: 0.006\n",
      "[226,    42] loss: 0.007\n",
      "[226,    49] loss: 0.007\n",
      "[226,    56] loss: 0.006\n",
      "[227,     7] loss: 0.007\n",
      "[227,    14] loss: 0.006\n",
      "[227,    21] loss: 0.006\n",
      "[227,    28] loss: 0.006\n",
      "[227,    35] loss: 0.009\n",
      "[227,    42] loss: 0.005\n",
      "[227,    49] loss: 0.007\n",
      "[227,    56] loss: 0.006\n",
      "[228,     7] loss: 0.006\n",
      "[228,    14] loss: 0.008\n",
      "[228,    21] loss: 0.007\n",
      "[228,    28] loss: 0.007\n",
      "[228,    35] loss: 0.008\n",
      "[228,    42] loss: 0.006\n",
      "[228,    49] loss: 0.008\n",
      "[228,    56] loss: 0.008\n",
      "[229,     7] loss: 0.007\n",
      "[229,    14] loss: 0.007\n",
      "[229,    21] loss: 0.007\n",
      "[229,    28] loss: 0.007\n",
      "[229,    35] loss: 0.007\n",
      "[229,    42] loss: 0.007\n",
      "[229,    49] loss: 0.007\n",
      "[229,    56] loss: 0.006\n",
      "[230,     7] loss: 0.007\n",
      "[230,    14] loss: 0.005\n",
      "[230,    21] loss: 0.008\n",
      "[230,    28] loss: 0.007\n",
      "[230,    35] loss: 0.008\n",
      "[230,    42] loss: 0.005\n",
      "[230,    49] loss: 0.008\n",
      "[230,    56] loss: 0.007\n",
      "[231,     7] loss: 0.007\n",
      "[231,    14] loss: 0.007\n",
      "[231,    21] loss: 0.007\n",
      "[231,    28] loss: 0.004\n",
      "[231,    35] loss: 0.006\n",
      "[231,    42] loss: 0.007\n",
      "[231,    49] loss: 0.008\n",
      "[231,    56] loss: 0.008\n",
      "[232,     7] loss: 0.006\n",
      "[232,    14] loss: 0.007\n",
      "[232,    21] loss: 0.007\n",
      "[232,    28] loss: 0.005\n",
      "[232,    35] loss: 0.007\n",
      "[232,    42] loss: 0.008\n",
      "[232,    49] loss: 0.008\n",
      "[232,    56] loss: 0.007\n",
      "[233,     7] loss: 0.008\n",
      "[233,    14] loss: 0.007\n",
      "[233,    21] loss: 0.008\n",
      "[233,    28] loss: 0.006\n",
      "[233,    35] loss: 0.008\n",
      "[233,    42] loss: 0.006\n",
      "[233,    49] loss: 0.006\n",
      "[233,    56] loss: 0.007\n",
      "[234,     7] loss: 0.006\n",
      "[234,    14] loss: 0.007\n",
      "[234,    21] loss: 0.008\n",
      "[234,    28] loss: 0.008\n",
      "[234,    35] loss: 0.006\n",
      "[234,    42] loss: 0.007\n",
      "[234,    49] loss: 0.007\n",
      "[234,    56] loss: 0.007\n",
      "[235,     7] loss: 0.006\n",
      "[235,    14] loss: 0.006\n",
      "[235,    21] loss: 0.006\n",
      "[235,    28] loss: 0.007\n",
      "[235,    35] loss: 0.007\n",
      "[235,    42] loss: 0.007\n",
      "[235,    49] loss: 0.007\n",
      "[235,    56] loss: 0.007\n",
      "[236,     7] loss: 0.007\n",
      "[236,    14] loss: 0.007\n",
      "[236,    21] loss: 0.007\n",
      "[236,    28] loss: 0.007\n",
      "[236,    35] loss: 0.006\n",
      "[236,    42] loss: 0.007\n",
      "[236,    49] loss: 0.008\n",
      "[236,    56] loss: 0.007\n",
      "[237,     7] loss: 0.006\n",
      "[237,    14] loss: 0.006\n",
      "[237,    21] loss: 0.007\n",
      "[237,    28] loss: 0.010\n",
      "[237,    35] loss: 0.007\n",
      "[237,    42] loss: 0.006\n",
      "[237,    49] loss: 0.006\n",
      "[237,    56] loss: 0.006\n",
      "[238,     7] loss: 0.006\n",
      "[238,    14] loss: 0.009\n",
      "[238,    21] loss: 0.008\n",
      "[238,    28] loss: 0.006\n",
      "[238,    35] loss: 0.007\n",
      "[238,    42] loss: 0.005\n",
      "[238,    49] loss: 0.007\n",
      "[238,    56] loss: 0.004\n",
      "[239,     7] loss: 0.005\n",
      "[239,    14] loss: 0.006\n",
      "[239,    21] loss: 0.007\n",
      "[239,    28] loss: 0.007\n",
      "[239,    35] loss: 0.007\n",
      "[239,    42] loss: 0.006\n",
      "[239,    49] loss: 0.007\n",
      "[239,    56] loss: 0.007\n",
      "[240,     7] loss: 0.006\n",
      "[240,    14] loss: 0.004\n",
      "[240,    21] loss: 0.008\n",
      "[240,    28] loss: 0.006\n",
      "[240,    35] loss: 0.009\n",
      "[240,    42] loss: 0.007\n",
      "[240,    49] loss: 0.007\n",
      "[240,    56] loss: 0.006\n",
      "[241,     7] loss: 0.006\n",
      "[241,    14] loss: 0.006\n",
      "[241,    21] loss: 0.006\n",
      "[241,    28] loss: 0.007\n",
      "[241,    35] loss: 0.006\n",
      "[241,    42] loss: 0.008\n",
      "[241,    49] loss: 0.007\n",
      "[241,    56] loss: 0.006\n",
      "[242,     7] loss: 0.006\n",
      "[242,    14] loss: 0.005\n",
      "[242,    21] loss: 0.008\n",
      "[242,    28] loss: 0.005\n",
      "[242,    35] loss: 0.008\n",
      "[242,    42] loss: 0.008\n",
      "[242,    49] loss: 0.006\n",
      "[242,    56] loss: 0.005\n",
      "[243,     7] loss: 0.007\n",
      "[243,    14] loss: 0.008\n",
      "[243,    21] loss: 0.007\n",
      "[243,    28] loss: 0.007\n",
      "[243,    35] loss: 0.007\n",
      "[243,    42] loss: 0.007\n",
      "[243,    49] loss: 0.006\n",
      "[243,    56] loss: 0.007\n",
      "[244,     7] loss: 0.008\n",
      "[244,    14] loss: 0.005\n",
      "[244,    21] loss: 0.007\n",
      "[244,    28] loss: 0.008\n",
      "[244,    35] loss: 0.007\n",
      "[244,    42] loss: 0.006\n",
      "[244,    49] loss: 0.008\n",
      "[244,    56] loss: 0.008\n",
      "[245,     7] loss: 0.007\n",
      "[245,    14] loss: 0.005\n",
      "[245,    21] loss: 0.005\n",
      "[245,    28] loss: 0.006\n",
      "[245,    35] loss: 0.004\n",
      "[245,    42] loss: 0.007\n",
      "[245,    49] loss: 0.007\n",
      "[245,    56] loss: 0.009\n",
      "[246,     7] loss: 0.007\n",
      "[246,    14] loss: 0.007\n",
      "[246,    21] loss: 0.007\n",
      "[246,    28] loss: 0.005\n",
      "[246,    35] loss: 0.006\n",
      "[246,    42] loss: 0.005\n",
      "[246,    49] loss: 0.006\n",
      "[246,    56] loss: 0.005\n",
      "[247,     7] loss: 0.005\n",
      "[247,    14] loss: 0.007\n",
      "[247,    21] loss: 0.005\n",
      "[247,    28] loss: 0.008\n",
      "[247,    35] loss: 0.006\n",
      "[247,    42] loss: 0.008\n",
      "[247,    49] loss: 0.007\n",
      "[247,    56] loss: 0.007\n",
      "[248,     7] loss: 0.006\n",
      "[248,    14] loss: 0.006\n",
      "[248,    21] loss: 0.006\n",
      "[248,    28] loss: 0.007\n",
      "[248,    35] loss: 0.004\n",
      "[248,    42] loss: 0.007\n",
      "[248,    49] loss: 0.006\n",
      "[248,    56] loss: 0.006\n",
      "[249,     7] loss: 0.006\n",
      "[249,    14] loss: 0.005\n",
      "[249,    21] loss: 0.006\n",
      "[249,    28] loss: 0.007\n",
      "[249,    35] loss: 0.007\n",
      "[249,    42] loss: 0.007\n",
      "[249,    49] loss: 0.006\n",
      "[249,    56] loss: 0.009\n",
      "[250,     7] loss: 0.005\n",
      "[250,    14] loss: 0.006\n",
      "[250,    21] loss: 0.005\n",
      "[250,    28] loss: 0.007\n",
      "[250,    35] loss: 0.006\n",
      "[250,    42] loss: 0.005\n",
      "[250,    49] loss: 0.008\n",
      "[250,    56] loss: 0.005\n",
      "[251,     7] loss: 0.005\n",
      "[251,    14] loss: 0.007\n",
      "[251,    21] loss: 0.006\n",
      "[251,    28] loss: 0.008\n",
      "[251,    35] loss: 0.006\n",
      "[251,    42] loss: 0.007\n",
      "[251,    49] loss: 0.006\n",
      "[251,    56] loss: 0.007\n",
      "[252,     7] loss: 0.006\n",
      "[252,    14] loss: 0.006\n",
      "[252,    21] loss: 0.005\n",
      "[252,    28] loss: 0.006\n",
      "[252,    35] loss: 0.008\n",
      "[252,    42] loss: 0.007\n",
      "[252,    49] loss: 0.007\n",
      "[252,    56] loss: 0.007\n",
      "[253,     7] loss: 0.006\n",
      "[253,    14] loss: 0.006\n",
      "[253,    21] loss: 0.006\n",
      "[253,    28] loss: 0.007\n",
      "[253,    35] loss: 0.007\n",
      "[253,    42] loss: 0.007\n",
      "[253,    49] loss: 0.006\n",
      "[253,    56] loss: 0.007\n",
      "[254,     7] loss: 0.008\n",
      "[254,    14] loss: 0.007\n",
      "[254,    21] loss: 0.006\n",
      "[254,    28] loss: 0.005\n",
      "[254,    35] loss: 0.008\n",
      "[254,    42] loss: 0.007\n",
      "[254,    49] loss: 0.006\n",
      "[254,    56] loss: 0.008\n",
      "[255,     7] loss: 0.006\n",
      "[255,    14] loss: 0.007\n",
      "[255,    21] loss: 0.006\n",
      "[255,    28] loss: 0.005\n",
      "[255,    35] loss: 0.006\n",
      "[255,    42] loss: 0.006\n",
      "[255,    49] loss: 0.006\n",
      "[255,    56] loss: 0.005\n",
      "[256,     7] loss: 0.006\n",
      "[256,    14] loss: 0.008\n",
      "[256,    21] loss: 0.006\n",
      "[256,    28] loss: 0.005\n",
      "[256,    35] loss: 0.006\n",
      "[256,    42] loss: 0.007\n",
      "[256,    49] loss: 0.005\n",
      "[256,    56] loss: 0.005\n",
      "[257,     7] loss: 0.005\n",
      "[257,    14] loss: 0.005\n",
      "[257,    21] loss: 0.007\n",
      "[257,    28] loss: 0.006\n",
      "[257,    35] loss: 0.006\n",
      "[257,    42] loss: 0.006\n",
      "[257,    49] loss: 0.006\n",
      "[257,    56] loss: 0.008\n",
      "[258,     7] loss: 0.006\n",
      "[258,    14] loss: 0.005\n",
      "[258,    21] loss: 0.007\n",
      "[258,    28] loss: 0.006\n",
      "[258,    35] loss: 0.006\n",
      "[258,    42] loss: 0.006\n",
      "[258,    49] loss: 0.006\n",
      "[258,    56] loss: 0.008\n",
      "[259,     7] loss: 0.006\n",
      "[259,    14] loss: 0.005\n",
      "[259,    21] loss: 0.004\n",
      "[259,    28] loss: 0.006\n",
      "[259,    35] loss: 0.007\n",
      "[259,    42] loss: 0.008\n",
      "[259,    49] loss: 0.007\n",
      "[259,    56] loss: 0.006\n",
      "[260,     7] loss: 0.004\n",
      "[260,    14] loss: 0.008\n",
      "[260,    21] loss: 0.005\n",
      "[260,    28] loss: 0.005\n",
      "[260,    35] loss: 0.006\n",
      "[260,    42] loss: 0.006\n",
      "[260,    49] loss: 0.005\n",
      "[260,    56] loss: 0.006\n",
      "[261,     7] loss: 0.006\n",
      "[261,    14] loss: 0.006\n",
      "[261,    21] loss: 0.005\n",
      "[261,    28] loss: 0.006\n",
      "[261,    35] loss: 0.005\n",
      "[261,    42] loss: 0.007\n",
      "[261,    49] loss: 0.006\n",
      "[261,    56] loss: 0.006\n",
      "[262,     7] loss: 0.006\n",
      "[262,    14] loss: 0.005\n",
      "[262,    21] loss: 0.005\n",
      "[262,    28] loss: 0.007\n",
      "[262,    35] loss: 0.009\n",
      "[262,    42] loss: 0.004\n",
      "[262,    49] loss: 0.006\n",
      "[262,    56] loss: 0.005\n",
      "[263,     7] loss: 0.005\n",
      "[263,    14] loss: 0.006\n",
      "[263,    21] loss: 0.005\n",
      "[263,    28] loss: 0.006\n",
      "[263,    35] loss: 0.005\n",
      "[263,    42] loss: 0.007\n",
      "[263,    49] loss: 0.006\n",
      "[263,    56] loss: 0.007\n",
      "[264,     7] loss: 0.005\n",
      "[264,    14] loss: 0.007\n",
      "[264,    21] loss: 0.005\n",
      "[264,    28] loss: 0.006\n",
      "[264,    35] loss: 0.005\n",
      "[264,    42] loss: 0.006\n",
      "[264,    49] loss: 0.006\n",
      "[264,    56] loss: 0.006\n",
      "[265,     7] loss: 0.008\n",
      "[265,    14] loss: 0.005\n",
      "[265,    21] loss: 0.006\n",
      "[265,    28] loss: 0.005\n",
      "[265,    35] loss: 0.005\n",
      "[265,    42] loss: 0.005\n",
      "[265,    49] loss: 0.008\n",
      "[265,    56] loss: 0.005\n",
      "[266,     7] loss: 0.007\n",
      "[266,    14] loss: 0.005\n",
      "[266,    21] loss: 0.005\n",
      "[266,    28] loss: 0.007\n",
      "[266,    35] loss: 0.006\n",
      "[266,    42] loss: 0.007\n",
      "[266,    49] loss: 0.005\n",
      "[266,    56] loss: 0.004\n",
      "[267,     7] loss: 0.005\n",
      "[267,    14] loss: 0.006\n",
      "[267,    21] loss: 0.006\n",
      "[267,    28] loss: 0.008\n",
      "[267,    35] loss: 0.006\n",
      "[267,    42] loss: 0.007\n",
      "[267,    49] loss: 0.005\n",
      "[267,    56] loss: 0.007\n",
      "[268,     7] loss: 0.008\n",
      "[268,    14] loss: 0.006\n",
      "[268,    21] loss: 0.005\n",
      "[268,    28] loss: 0.007\n",
      "[268,    35] loss: 0.006\n",
      "[268,    42] loss: 0.006\n",
      "[268,    49] loss: 0.006\n",
      "[268,    56] loss: 0.005\n",
      "[269,     7] loss: 0.004\n",
      "[269,    14] loss: 0.004\n",
      "[269,    21] loss: 0.007\n",
      "[269,    28] loss: 0.006\n",
      "[269,    35] loss: 0.007\n",
      "[269,    42] loss: 0.006\n",
      "[269,    49] loss: 0.006\n",
      "[269,    56] loss: 0.007\n",
      "[270,     7] loss: 0.006\n",
      "[270,    14] loss: 0.004\n",
      "[270,    21] loss: 0.006\n",
      "[270,    28] loss: 0.007\n",
      "[270,    35] loss: 0.006\n",
      "[270,    42] loss: 0.005\n",
      "[270,    49] loss: 0.005\n",
      "[270,    56] loss: 0.006\n",
      "[271,     7] loss: 0.007\n",
      "[271,    14] loss: 0.006\n",
      "[271,    21] loss: 0.006\n",
      "[271,    28] loss: 0.007\n",
      "[271,    35] loss: 0.005\n",
      "[271,    42] loss: 0.006\n",
      "[271,    49] loss: 0.006\n",
      "[271,    56] loss: 0.006\n",
      "[272,     7] loss: 0.005\n",
      "[272,    14] loss: 0.007\n",
      "[272,    21] loss: 0.008\n",
      "[272,    28] loss: 0.007\n",
      "[272,    35] loss: 0.005\n",
      "[272,    42] loss: 0.005\n",
      "[272,    49] loss: 0.006\n",
      "[272,    56] loss: 0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 13\u001B[0m\n\u001B[0;32m     10\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     11\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_num, batch_data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;66;03m#print(\"Epoch {0} Batch {1}\".format(epoch+1, batch_num+1))\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     Optimiser\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     17\u001B[0m     data, labels \u001B[38;5;241m=\u001B[39m batch_data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1282\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m   1283\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_thread\u001B[38;5;241m.\u001B[39mis_alive():\n\u001B[1;32m-> 1284\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_get_data()\n\u001B[0;32m   1285\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1286\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1132\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_queue\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m   1133\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1134\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\Lib\\queue.py:180\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    178\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m remaining \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[0;32m    179\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m--> 180\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_empty\u001B[38;5;241m.\u001B[39mwait(remaining)\n\u001B[0;32m    181\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get()\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_full\u001B[38;5;241m.\u001B[39mnotify()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\MachineLearning\\Lib\\threading.py:324\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    323\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 324\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mTrue\u001B[39;00m, timeout)\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    326\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "Optimiser = optim.AdamW(model.parameters(), lr=1e-2, eps=1e-4, weight_decay=1e-6)\n",
    "model.train(True)\n",
    "accuracy_test_freq = 1\n",
    "\n",
    "for epoch in range(0,1000):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_num, batch_data in enumerate(train_dataloader):\n",
    "        #print(\"Epoch {0} Batch {1}\".format(epoch+1, batch_num+1))\n",
    "        Optimiser.zero_grad()\n",
    "        \n",
    "        data, labels = batch_data\n",
    "        #labels = nn.functional.one_hot(labels, num_classes = 47).float()\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        prediction = model(data)\n",
    "        _, predicted = torch.max(prediction, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        loss = loss_fn(prediction,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        log_num = int(batch_count/8)\n",
    "        if log_num == 1:\n",
    "            print(f'[{epoch + 1}, {batch_num + 1:5d}] loss: {batch_loss:.3f}')\n",
    "            writer.add_scalar(\"Loss/Train\", batch_loss / log_num, epoch_count * batch_count + batch_num)\n",
    "            writer.add_scalar(\"Accuracy/Train\", (correct/total) * 100, epoch_count * batch_count + batch_num)\n",
    "            batch_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "        else:\n",
    "            if batch_num % log_num == (log_num-1):\n",
    "                print(f'[{epoch + 1}, {batch_num + 1:5d}] loss: {batch_loss / log_num:.3f}')\n",
    "                writer.add_scalar(\"Loss/Train\", batch_loss / log_num, epoch_count * batch_count + batch_num)\n",
    "                writer.add_scalar(\"Accuracy/Train\", (correct/total) * 100, epoch_count * batch_count + batch_num )\n",
    "                batch_loss = 0.0\n",
    "                total = 0\n",
    "                correct = 0\n",
    "        Optimiser.step()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "    if (epoch+1) % accuracy_test_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            model.train(False)\n",
    "            for loader_data in test_dataloader:\n",
    "                data, labels = loader_data\n",
    "                data = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "                output = model(data)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            model.train(True)\n",
    "        writer.add_scalar(\"Accuracy/Test\", (correct/total) * 100, epoch_count + 1)\n",
    "        \n",
    "    epoch_count += 1\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T20:19:00.314421200Z",
     "start_time": "2023-08-22T18:41:25.003333900Z"
    }
   },
   "id": "697d6e4ebb7453a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for loader_data in test_dataloader:\n",
    "        data, labels = loader_data\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print((correct/total) * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-22T20:19:00.316825Z",
     "start_time": "2023-08-22T20:19:00.314421200Z"
    }
   },
   "id": "c2fc88e609895843"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
